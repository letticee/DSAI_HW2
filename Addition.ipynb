{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 80000\n",
    "DIGITS = 3\n",
    "REVERSE = False\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789+ '\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '+',\n",
       " 2: '0',\n",
       " 3: '1',\n",
       " 4: '2',\n",
       " 5: '3',\n",
       " 6: '4',\n",
       " 7: '5',\n",
       " 8: '6',\n",
       " 9: '7',\n",
       " 10: '8',\n",
       " 11: '9'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctable.indices_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 80000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['87+67  ', '4+205  ', '7+5    ', '551+0  ', '223+326'] ['154 ', '209 ', '12  ', '551 ', '549 ']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5], expected[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(expected), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(18000, 7, 12)\n",
      "(18000, 4, 12)\n",
      "Validation Data:\n",
      "(2000, 7, 12)\n",
      "(2000, 4, 12)\n",
      "Testing Data:\n",
      "(60000, 7, 12)\n",
      "(60000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# train_test_split\n",
    "train_x = x[:20000]\n",
    "train_y = y[:20000]\n",
    "test_x = x[20000:]\n",
    "test_y = y[20000:]\n",
    "\n",
    "split_at = len(train_x) - len(train_x) // 10\n",
    "(x_train, x_val) = train_x[:split_at], train_x[split_at:]\n",
    "(y_train, y_val) = train_y[:split_at], train_y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  [[[False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False  True False False False False False False False\n",
      "   False]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False  True False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False  True\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False  True False False False\n",
      "   False]\n",
      "  [False False False False False False False False False  True False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False  True False False False\n",
      "   False]\n",
      "  [False False False False False False  True False False False False\n",
      "   False]]] \n",
      "\n",
      " label:  [[[False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]\n",
      "  [False False False False False False False False False False  True\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False  True False False False False False False False\n",
      "   False]\n",
      "  [False False False  True False False False False False False False\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"input: \", x_train[:3], '\\n\\n', \"label: \", y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\SCREAM\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "############################################\n",
    "##### Build your own model here ############\n",
    "############################################\n",
    "model = Sequential()\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "for _ in range(LAYERS):\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SCREAM\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "18000/18000 [==============================] - 9s 493us/step - loss: 2.0258 - acc: 0.2868 - val_loss: 1.8685 - val_acc: 0.3244\n",
      "Epoch 2/200\n",
      "18000/18000 [==============================] - 4s 204us/step - loss: 1.8568 - acc: 0.3299 - val_loss: 1.8325 - val_acc: 0.3310\n",
      "Epoch 3/200\n",
      "18000/18000 [==============================] - 4s 197us/step - loss: 1.8182 - acc: 0.3306 - val_loss: 1.8067 - val_acc: 0.3326\n",
      "Epoch 4/200\n",
      "18000/18000 [==============================] - 4s 200us/step - loss: 1.7871 - acc: 0.3373 - val_loss: 1.7724 - val_acc: 0.3438\n",
      "Epoch 5/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 1.7319 - acc: 0.3565 - val_loss: 1.7229 - val_acc: 0.3629\n",
      "Epoch 6/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 1.6624 - acc: 0.3776 - val_loss: 1.6474 - val_acc: 0.3754\n",
      "Epoch 7/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 1.5923 - acc: 0.3998 - val_loss: 1.5569 - val_acc: 0.4081\n",
      "Epoch 8/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 1.5346 - acc: 0.4210 - val_loss: 1.5184 - val_acc: 0.4228\n",
      "Epoch 9/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 1.4732 - acc: 0.4452 - val_loss: 1.4724 - val_acc: 0.4436\n",
      "Epoch 10/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 1.4230 - acc: 0.4650 - val_loss: 1.4109 - val_acc: 0.4700\n",
      "Epoch 11/200\n",
      "18000/18000 [==============================] - 3s 177us/step - loss: 1.3811 - acc: 0.4825 - val_loss: 1.3692 - val_acc: 0.4851\n",
      "Epoch 12/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 1.3340 - acc: 0.5034 - val_loss: 1.3217 - val_acc: 0.5086\n",
      "Epoch 13/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 1.2964 - acc: 0.5182 - val_loss: 1.2734 - val_acc: 0.5258\n",
      "Epoch 14/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 1.2552 - acc: 0.5359 - val_loss: 1.2658 - val_acc: 0.5242\n",
      "Epoch 15/200\n",
      "18000/18000 [==============================] - 3s 189us/step - loss: 1.2174 - acc: 0.5505 - val_loss: 1.2067 - val_acc: 0.5464\n",
      "Epoch 16/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 1.1752 - acc: 0.5659 - val_loss: 1.1732 - val_acc: 0.5631\n",
      "Epoch 17/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 1.1418 - acc: 0.5762 - val_loss: 1.1451 - val_acc: 0.5659\n",
      "Epoch 18/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 1.1121 - acc: 0.5851 - val_loss: 1.1144 - val_acc: 0.5758\n",
      "Epoch 19/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 1.0738 - acc: 0.6008 - val_loss: 1.0834 - val_acc: 0.5910\n",
      "Epoch 20/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 1.0400 - acc: 0.6114 - val_loss: 1.0471 - val_acc: 0.6004\n",
      "Epoch 21/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 1.0029 - acc: 0.6284 - val_loss: 1.0169 - val_acc: 0.6107\n",
      "Epoch 22/200\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 0.9736 - acc: 0.6377 - val_loss: 0.9857 - val_acc: 0.6246\n",
      "Epoch 23/200\n",
      "18000/18000 [==============================] - 4s 223us/step - loss: 0.9365 - acc: 0.6541 - val_loss: 0.9551 - val_acc: 0.6362\n",
      "Epoch 24/200\n",
      "18000/18000 [==============================] - 4s 223us/step - loss: 0.8989 - acc: 0.6690 - val_loss: 0.9219 - val_acc: 0.6553\n",
      "Epoch 25/200\n",
      "18000/18000 [==============================] - 4s 213us/step - loss: 0.8522 - acc: 0.6882 - val_loss: 0.8777 - val_acc: 0.6689\n",
      "Epoch 26/200\n",
      "18000/18000 [==============================] - 4s 212us/step - loss: 0.7999 - acc: 0.7064 - val_loss: 0.8180 - val_acc: 0.6950\n",
      "Epoch 27/200\n",
      "18000/18000 [==============================] - 3s 192us/step - loss: 0.7375 - acc: 0.7299 - val_loss: 0.7558 - val_acc: 0.7189\n",
      "Epoch 28/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.6753 - acc: 0.7562 - val_loss: 0.6963 - val_acc: 0.7349\n",
      "Epoch 29/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.6039 - acc: 0.7866 - val_loss: 0.6065 - val_acc: 0.7783\n",
      "Epoch 30/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.5352 - acc: 0.8201 - val_loss: 0.5512 - val_acc: 0.7965\n",
      "Epoch 31/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.4806 - acc: 0.8426 - val_loss: 0.4867 - val_acc: 0.8400\n",
      "Epoch 32/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.4319 - acc: 0.8655 - val_loss: 0.4724 - val_acc: 0.8367\n",
      "Epoch 33/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.3933 - acc: 0.8834 - val_loss: 0.4012 - val_acc: 0.8731\n",
      "Epoch 34/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.3489 - acc: 0.9049 - val_loss: 0.3638 - val_acc: 0.8879\n",
      "Epoch 35/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.3157 - acc: 0.9185 - val_loss: 0.3502 - val_acc: 0.8884\n",
      "Epoch 36/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.2886 - acc: 0.9284 - val_loss: 0.3217 - val_acc: 0.9020\n",
      "Epoch 37/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.2701 - acc: 0.9327 - val_loss: 0.2948 - val_acc: 0.9182\n",
      "Epoch 38/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.2579 - acc: 0.9359 - val_loss: 0.2612 - val_acc: 0.9292\n",
      "Epoch 39/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.2170 - acc: 0.9534 - val_loss: 0.2488 - val_acc: 0.9321\n",
      "Epoch 40/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.2134 - acc: 0.9512 - val_loss: 0.2256 - val_acc: 0.9417\n",
      "Epoch 41/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.1835 - acc: 0.9629 - val_loss: 0.2212 - val_acc: 0.9366\n",
      "Epoch 42/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.1733 - acc: 0.9645 - val_loss: 0.1934 - val_acc: 0.9509\n",
      "Epoch 43/200\n",
      "18000/18000 [==============================] - 3s 189us/step - loss: 0.1533 - acc: 0.9714 - val_loss: 0.1864 - val_acc: 0.9510\n",
      "Epoch 44/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.1484 - acc: 0.9701 - val_loss: 0.1874 - val_acc: 0.9480\n",
      "Epoch 45/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.1313 - acc: 0.9757 - val_loss: 0.1674 - val_acc: 0.9535\n",
      "Epoch 46/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.1220 - acc: 0.9784 - val_loss: 0.1623 - val_acc: 0.9555\n",
      "Epoch 47/200\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.1195 - acc: 0.9774 - val_loss: 0.1580 - val_acc: 0.9529\n",
      "Epoch 48/200\n",
      "18000/18000 [==============================] - 4s 205us/step - loss: 0.1071 - acc: 0.9805 - val_loss: 0.1248 - val_acc: 0.9694\n",
      "Epoch 49/200\n",
      "18000/18000 [==============================] - 4s 197us/step - loss: 0.0940 - acc: 0.9856 - val_loss: 0.1313 - val_acc: 0.9619\n",
      "Epoch 50/200\n",
      "18000/18000 [==============================] - 4s 219us/step - loss: 0.1036 - acc: 0.9797 - val_loss: 0.1424 - val_acc: 0.9573\n",
      "Epoch 51/200\n",
      "18000/18000 [==============================] - 3s 191us/step - loss: 0.0901 - acc: 0.9841 - val_loss: 0.1093 - val_acc: 0.9711\n",
      "Epoch 52/200\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 0.0738 - acc: 0.9898 - val_loss: 0.1096 - val_acc: 0.9702ss: 0.0737 \n",
      "Epoch 53/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 0.0991 - acc: 0.9766 - val_loss: 0.1292 - val_acc: 0.9607\n",
      "Epoch 54/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0728 - acc: 0.9877 - val_loss: 0.0911 - val_acc: 0.9768\n",
      "Epoch 55/200\n",
      "18000/18000 [==============================] - 4s 227us/step - loss: 0.0620 - acc: 0.9911 - val_loss: 0.0904 - val_acc: 0.9740\n",
      "Epoch 56/200\n",
      "18000/18000 [==============================] - 4s 205us/step - loss: 0.0540 - acc: 0.9936 - val_loss: 0.0878 - val_acc: 0.9746\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 4s 200us/step - loss: 0.0523 - acc: 0.9931 - val_loss: 0.1055 - val_acc: 0.9692\n",
      "Epoch 58/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 0.0803 - acc: 0.9802 - val_loss: 0.1005 - val_acc: 0.9715\n",
      "Epoch 59/200\n",
      "18000/18000 [==============================] - 3s 192us/step - loss: 0.0627 - acc: 0.9873 - val_loss: 0.0850 - val_acc: 0.9757\n",
      "Epoch 60/200\n",
      "18000/18000 [==============================] - 3s 192us/step - loss: 0.0512 - acc: 0.9913 - val_loss: 0.0788 - val_acc: 0.9781\n",
      "Epoch 61/200\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 0.0395 - acc: 0.9957 - val_loss: 0.0685 - val_acc: 0.9806\n",
      "Epoch 62/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 0.0423 - acc: 0.9935 - val_loss: 0.0968 - val_acc: 0.9695\n",
      "Epoch 63/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.0632 - acc: 0.9855 - val_loss: 0.2364 - val_acc: 0.9266\n",
      "Epoch 64/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.1275 - acc: 0.9607 - val_loss: 0.0686 - val_acc: 0.9805\n",
      "Epoch 65/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 0.0336 - acc: 0.9964 - val_loss: 0.0566 - val_acc: 0.9857\n",
      "Epoch 66/200\n",
      "18000/18000 [==============================] - 3s 191us/step - loss: 0.0292 - acc: 0.9975 - val_loss: 0.0565 - val_acc: 0.9856\n",
      "Epoch 67/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0262 - acc: 0.9981 - val_loss: 0.0526 - val_acc: 0.9852\n",
      "Epoch 68/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0253 - acc: 0.9980 - val_loss: 0.0548 - val_acc: 0.9835\n",
      "Epoch 69/200\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.0240 - acc: 0.9980 - val_loss: 0.0539 - val_acc: 0.9850\n",
      "Epoch 70/200\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.0241 - acc: 0.9977 - val_loss: 0.0545 - val_acc: 0.9829\n",
      "Epoch 71/200\n",
      "18000/18000 [==============================] - ETA: 0s - loss: 0.0314 - acc: 0.994 - 3s 193us/step - loss: 0.0316 - acc: 0.9943 - val_loss: 0.0849 - val_acc: 0.9711\n",
      "Epoch 72/200\n",
      "18000/18000 [==============================] - 4s 215us/step - loss: 0.0743 - acc: 0.9777 - val_loss: 0.0682 - val_acc: 0.9770\n",
      "Epoch 73/200\n",
      "18000/18000 [==============================] - 4s 201us/step - loss: 0.0273 - acc: 0.9963 - val_loss: 0.0540 - val_acc: 0.9834\n",
      "Epoch 74/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0204 - acc: 0.9977 - val_loss: 0.0485 - val_acc: 0.9852\n",
      "Epoch 75/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.0179 - acc: 0.9987 - val_loss: 0.0461 - val_acc: 0.9852\n",
      "Epoch 76/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0181 - acc: 0.9981 - val_loss: 0.0491 - val_acc: 0.9846\n",
      "Epoch 77/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0304 - acc: 0.9931 - val_loss: 0.1621 - val_acc: 0.9395\n",
      "Epoch 78/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.1227 - acc: 0.9604 - val_loss: 0.0552 - val_acc: 0.9831\n",
      "Epoch 79/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 0.0185 - acc: 0.9984 - val_loss: 0.0420 - val_acc: 0.9867\n",
      "Epoch 80/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0144 - acc: 0.9993 - val_loss: 0.0409 - val_acc: 0.9886\n",
      "Epoch 81/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0132 - acc: 0.9992 - val_loss: 0.0393 - val_acc: 0.9889\n",
      "Epoch 82/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0129 - acc: 0.9990 - val_loss: 0.0420 - val_acc: 0.9865\n",
      "Epoch 83/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0123 - acc: 0.9993 - val_loss: 0.0404 - val_acc: 0.9879\n",
      "Epoch 84/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0118 - acc: 0.9992 - val_loss: 0.0403 - val_acc: 0.9870\n",
      "Epoch 85/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0120 - acc: 0.9988 - val_loss: 0.0430 - val_acc: 0.9862\n",
      "Epoch 86/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 0.0146 - acc: 0.9979 - val_loss: 0.0598 - val_acc: 0.9796\n",
      "Epoch 87/200\n",
      "18000/18000 [==============================] - 4s 210us/step - loss: 0.0617 - acc: 0.9814 - val_loss: 0.2773 - val_acc: 0.9035\n",
      "Epoch 88/200\n",
      "18000/18000 [==============================] - 4s 212us/step - loss: 0.0671 - acc: 0.9787 - val_loss: 0.0471 - val_acc: 0.9852\n",
      "Epoch 89/200\n",
      "18000/18000 [==============================] - 4s 210us/step - loss: 0.0132 - acc: 0.9988 - val_loss: 0.0374 - val_acc: 0.9885\n",
      "Epoch 90/200\n",
      "18000/18000 [==============================] - 4s 232us/step - loss: 0.0097 - acc: 0.9995 - val_loss: 0.0346 - val_acc: 0.9890\n",
      "Epoch 91/200\n",
      "18000/18000 [==============================] - ETA: 0s - loss: 0.0089 - acc: 0.999 - 4s 224us/step - loss: 0.0089 - acc: 0.9996 - val_loss: 0.0342 - val_acc: 0.9891\n",
      "Epoch 92/200\n",
      "18000/18000 [==============================] - 4s 220us/step - loss: 0.0085 - acc: 0.9995 - val_loss: 0.0374 - val_acc: 0.9875\n",
      "Epoch 93/200\n",
      "18000/18000 [==============================] - 3s 189us/step - loss: 0.0094 - acc: 0.9993 - val_loss: 0.0392 - val_acc: 0.9881\n",
      "Epoch 94/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0093 - acc: 0.9992 - val_loss: 0.0361 - val_acc: 0.9880\n",
      "Epoch 95/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0093 - acc: 0.9989 - val_loss: 0.0415 - val_acc: 0.9860\n",
      "Epoch 96/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0247 - acc: 0.9933 - val_loss: 0.0811 - val_acc: 0.9727\n",
      "Epoch 97/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 0.1183 - acc: 0.9622 - val_loss: 0.0518 - val_acc: 0.9849\n",
      "Epoch 98/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0131 - acc: 0.9984 - val_loss: 0.0349 - val_acc: 0.9895\n",
      "Epoch 99/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0075 - acc: 0.9998 - val_loss: 0.0327 - val_acc: 0.9895\n",
      "Epoch 100/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0068 - acc: 0.9997 - val_loss: 0.0321 - val_acc: 0.9901\n",
      "Epoch 101/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0063 - acc: 0.9998 - val_loss: 0.0349 - val_acc: 0.9884\n",
      "Epoch 102/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0071 - acc: 0.9994 - val_loss: 0.0330 - val_acc: 0.9896\n",
      "Epoch 103/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0065 - acc: 0.9996 - val_loss: 0.0373 - val_acc: 0.9884\n",
      "Epoch 104/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0059 - acc: 0.9997 - val_loss: 0.0359 - val_acc: 0.9879\n",
      "Epoch 105/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.0312 - val_acc: 0.9898\n",
      "Epoch 106/200\n",
      "18000/18000 [==============================] - 3s 194us/step - loss: 0.0062 - acc: 0.9994 - val_loss: 0.0373 - val_acc: 0.9868\n",
      "Epoch 107/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0563 - acc: 0.9812 - val_loss: 0.1184 - val_acc: 0.9598\n",
      "Epoch 108/200\n",
      "18000/18000 [==============================] - 3s 192us/step - loss: 0.0520 - acc: 0.9837 - val_loss: 0.0531 - val_acc: 0.9844\n",
      "Epoch 109/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0085 - acc: 0.9994 - val_loss: 0.0314 - val_acc: 0.9900\n",
      "Epoch 110/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.0297 - val_acc: 0.9906\n",
      "Epoch 111/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0280 - val_acc: 0.9908\n",
      "Epoch 112/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0055 - acc: 0.9995 - val_loss: 0.0363 - val_acc: 0.9877\n",
      "Epoch 113/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0052 - acc: 0.9995 - val_loss: 0.0300 - val_acc: 0.9904\n",
      "Epoch 114/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0319 - val_acc: 0.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0043 - acc: 0.9998 - val_loss: 0.0291 - val_acc: 0.9900\n",
      "Epoch 116/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0042 - acc: 0.9997 - val_loss: 0.0279 - val_acc: 0.9909\n",
      "Epoch 117/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0044 - acc: 0.9997 - val_loss: 0.0336 - val_acc: 0.9890\n",
      "Epoch 118/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0499 - acc: 0.9859 - val_loss: 0.5372 - val_acc: 0.8568\n",
      "Epoch 119/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0878 - acc: 0.9716 - val_loss: 0.0464 - val_acc: 0.9840\n",
      "Epoch 120/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.0088 - acc: 0.9991 - val_loss: 0.0278 - val_acc: 0.9904\n",
      "Epoch 121/200\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.0048 - acc: 0.9998 - val_loss: 0.0269 - val_acc: 0.9916\n",
      "Epoch 122/200\n",
      "18000/18000 [==============================] - 4s 198us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.0269 - val_acc: 0.9909\n",
      "Epoch 123/200\n",
      "18000/18000 [==============================] - 3s 193us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.0272 - val_acc: 0.9908\n",
      "Epoch 124/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 0.9913\n",
      "Epoch 125/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.0269 - val_acc: 0.9908\n",
      "Epoch 126/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 0.0035 - acc: 0.9998 - val_loss: 0.0311 - val_acc: 0.9901\n",
      "Epoch 127/200\n",
      "18000/18000 [==============================] - 4s 220us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0381 - val_acc: 0.9883\n",
      "Epoch 128/200\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0443 - val_acc: 0.9855\n",
      "Epoch 129/200\n",
      "18000/18000 [==============================] - 4s 207us/step - loss: 0.0822 - acc: 0.9721 - val_loss: 0.1166 - val_acc: 0.9607\n",
      "Epoch 130/200\n",
      "18000/18000 [==============================] - 4s 208us/step - loss: 0.0350 - acc: 0.9893 - val_loss: 0.0431 - val_acc: 0.9846\n",
      "Epoch 131/200\n",
      "18000/18000 [==============================] - 4s 207us/step - loss: 0.0057 - acc: 0.9996 - val_loss: 0.0257 - val_acc: 0.9906\n",
      "Epoch 132/200\n",
      "18000/18000 [==============================] - 4s 195us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 0.9911\n",
      "Epoch 133/200\n",
      "18000/18000 [==============================] - 4s 202us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.0237 - val_acc: 0.9919\n",
      "Epoch 134/200\n",
      "18000/18000 [==============================] - 4s 195us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9909\n",
      "Epoch 135/200\n",
      "18000/18000 [==============================] - 4s 200us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9920\n",
      "Epoch 136/200\n",
      "18000/18000 [==============================] - 3s 189us/step - loss: 0.0028 - acc: 0.9999 - val_loss: 0.0248 - val_acc: 0.9911\n",
      "Epoch 137/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 0.9904\n",
      "Epoch 138/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9906\n",
      "Epoch 139/200\n",
      "18000/18000 [==============================] - 4s 200us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 0.9909\n",
      "Epoch 140/200\n",
      "18000/18000 [==============================] - 3s 184us/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0266 - val_acc: 0.9902\n",
      "Epoch 141/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0828 - val_acc: 0.9736\n",
      "Epoch 142/200\n",
      "18000/18000 [==============================] - 3s 179us/step - loss: 0.1439 - acc: 0.9558 - val_loss: 0.0709 - val_acc: 0.9765\n",
      "Epoch 143/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0110 - acc: 0.9978 - val_loss: 0.0318 - val_acc: 0.9885\n",
      "Epoch 144/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0247 - val_acc: 0.9916\n",
      "Epoch 145/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9922\n",
      "Epoch 146/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9928\n",
      "Epoch 147/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9925\n",
      "Epoch 148/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "Epoch 149/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9920\n",
      "Epoch 150/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9920\n",
      "Epoch 151/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 0.9925\n",
      "Epoch 152/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9915\n",
      "Epoch 153/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9909\n",
      "Epoch 154/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9925\n",
      "Epoch 155/200\n",
      "18000/18000 [==============================] - 3s 189us/step - loss: 0.0024 - acc: 0.9998 - val_loss: 0.0318 - val_acc: 0.9886\n",
      "Epoch 156/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.1177 - acc: 0.9620 - val_loss: 0.0912 - val_acc: 0.9694\n",
      "Epoch 157/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.0194 - acc: 0.9946 - val_loss: 0.0301 - val_acc: 0.9900\n",
      "Epoch 158/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0042 - acc: 0.9997 - val_loss: 0.0223 - val_acc: 0.9934\n",
      "Epoch 159/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 0.9937\n",
      "Epoch 160/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9935\n",
      "Epoch 161/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9929\n",
      "Epoch 162/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9935\n",
      "Epoch 163/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9931\n",
      "Epoch 164/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9928\n",
      "Epoch 165/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 0.9925\n",
      "Epoch 166/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9936\n",
      "Epoch 167/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0259 - acc: 0.9921 - val_loss: 0.1914 - val_acc: 0.9425\n",
      "Epoch 168/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0932 - acc: 0.9701 - val_loss: 0.0456 - val_acc: 0.9850\n",
      "Epoch 169/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0259 - val_acc: 0.9915\n",
      "Epoch 170/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.0031 - acc: 0.9999 - val_loss: 0.0232 - val_acc: 0.9926\n",
      "Epoch 171/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9931\n",
      "Epoch 172/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9943\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9938\n",
      "Epoch 174/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 0.9945\n",
      "Epoch 175/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9935\n",
      "Epoch 176/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9939\n",
      "Epoch 177/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9937\n",
      "Epoch 178/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 0.9942\n",
      "Epoch 179/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9934\n",
      "Epoch 180/200\n",
      "18000/18000 [==============================] - 3s 183us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9926\n",
      "Epoch 181/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0018 - acc: 0.9999 - val_loss: 0.0241 - val_acc: 0.9924\n",
      "Epoch 182/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0627 - acc: 0.9825 - val_loss: 0.2383 - val_acc: 0.9284\n",
      "Epoch 183/200\n",
      "18000/18000 [==============================] - 3s 182us/step - loss: 0.0598 - acc: 0.9803 - val_loss: 0.0456 - val_acc: 0.9839\n",
      "Epoch 184/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0068 - acc: 0.9988 - val_loss: 0.0220 - val_acc: 0.9929\n",
      "Epoch 185/200\n",
      "18000/18000 [==============================] - 3s 181us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9934\n",
      "Epoch 186/200\n",
      "18000/18000 [==============================] - 4s 205us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 0.9936\n",
      "Epoch 187/200\n",
      "18000/18000 [==============================] - 4s 232us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9932\n",
      "Epoch 188/200\n",
      "18000/18000 [==============================] - 4s 226us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9935\n",
      "Epoch 189/200\n",
      "18000/18000 [==============================] - 4s 205us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9936\n",
      "Epoch 190/200\n",
      "18000/18000 [==============================] - 4s 196us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9936\n",
      "Epoch 191/200\n",
      "18000/18000 [==============================] - 4s 211us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9933\n",
      "Epoch 192/200\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 0.9939\n",
      "Epoch 193/200\n",
      "18000/18000 [==============================] - 4s 210us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9940\n",
      "Epoch 194/200\n",
      "18000/18000 [==============================] - 4s 198us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 0.9935\n",
      "Epoch 195/200\n",
      "18000/18000 [==============================] - 4s 200us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 0.9937\n",
      "Epoch 196/200\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9940\n",
      "Epoch 197/200\n",
      "18000/18000 [==============================] - 4s 207us/step - loss: 9.9833e-04 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9940\n",
      "Epoch 198/200\n",
      "18000/18000 [==============================] - 4s 199us/step - loss: 0.0568 - acc: 0.9849 - val_loss: 0.2653 - val_acc: 0.9157\n",
      "Epoch 199/200\n",
      "18000/18000 [==============================] - 4s 197us/step - loss: 0.0685 - acc: 0.9774 - val_loss: 0.0373 - val_acc: 0.9876\n",
      "Epoch 200/200\n",
      "18000/18000 [==============================] - 4s 200us/step - loss: 0.0068 - acc: 0.9988 - val_loss: 0.0257 - val_acc: 0.9911\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training = model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=200,\n",
    "              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'3 digits add')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc = training.history['val_acc']\n",
    "acc = training.history['acc']\n",
    "plt.figure()\n",
    "plt.plot(val_acc, label = 'val_acc')\n",
    "plt.plot(acc, label = 'acc')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('3 digits add')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSG : Prediction\n",
      "30  Q 124+326 T 450  \u001b[91m☒\u001b[0m 440 \n",
      "63  Q 54+196  T 250  \u001b[91m☒\u001b[0m 240 \n",
      "66  Q 444+961 T 1405 \u001b[91m☒\u001b[0m 1305\n",
      "67  Q 272+28  T 300  \u001b[91m☒\u001b[0m 200 \n",
      "72  Q 149+0   T 149  \u001b[91m☒\u001b[0m 140 \n",
      "99  Q 855+45  T 900  \u001b[91m☒\u001b[0m 800 \n",
      "126  Q 324+77  T 401  \u001b[91m☒\u001b[0m 301 \n",
      "145  Q 581+9   T 590  \u001b[91m☒\u001b[0m 580 \n",
      "147  Q 0+147   T 147  \u001b[91m☒\u001b[0m 137 \n",
      "157  Q 28+62   T 90   \u001b[91m☒\u001b[0m 80  \n",
      "165  Q 593+6   T 599  \u001b[91m☒\u001b[0m 699 \n",
      "168  Q 403+491 T 894  \u001b[91m☒\u001b[0m 994 \n",
      "197  Q 0+6     T 6    \u001b[91m☒\u001b[0m 3   \n",
      "200  Q 722+284 T 1006 \u001b[91m☒\u001b[0m 9006\n",
      "246  Q 154+116 T 270  \u001b[91m☒\u001b[0m 260 \n",
      "302  Q 307+172 T 479  \u001b[91m☒\u001b[0m 489 \n",
      "418  Q 843+186 T 1029 \u001b[91m☒\u001b[0m 1039\n",
      "445  Q 444+961 T 1405 \u001b[91m☒\u001b[0m 1305\n",
      "472  Q 278+22  T 300  \u001b[91m☒\u001b[0m 390 \n",
      "482  Q 69+631  T 700  \u001b[91m☒\u001b[0m 600 \n",
      "524  Q 599+601 T 1200 \u001b[91m☒\u001b[0m 1290\n",
      "535  Q 35+75   T 110  \u001b[91m☒\u001b[0m 100 \n",
      "604  Q 898+694 T 1592 \u001b[91m☒\u001b[0m 1582\n",
      "608  Q 660+745 T 1405 \u001b[91m☒\u001b[0m 1305\n",
      "617  Q 181+821 T 1002 \u001b[91m☒\u001b[0m 902 \n",
      "661  Q 32+38   T 70   \u001b[91m☒\u001b[0m 60  \n",
      "699  Q 31+80   T 111  \u001b[91m☒\u001b[0m 112 \n",
      "731  Q 416+283 T 699  \u001b[91m☒\u001b[0m 709 \n",
      "734  Q 17+63   T 80   \u001b[91m☒\u001b[0m 70  \n",
      "739  Q 19+0    T 19   \u001b[91m☒\u001b[0m 29  \n",
      "745  Q 541+59  T 600  \u001b[91m☒\u001b[0m 500 \n",
      "802  Q 207+202 T 409  \u001b[91m☒\u001b[0m 419 \n",
      "886  Q 22+778  T 800  \u001b[91m☒\u001b[0m 700 \n",
      "917  Q 546+55  T 601  \u001b[91m☒\u001b[0m 501 \n",
      "922  Q 941+8   T 949  \u001b[91m☒\u001b[0m 959 \n",
      "926  Q 63+27   T 90   \u001b[91m☒\u001b[0m 80  \n",
      "949  Q 3+737   T 740  \u001b[91m☒\u001b[0m 730 \n",
      "986  Q 92+992  T 1084 \u001b[91m☒\u001b[0m 1083\n",
      "accu: 0.96505\n"
     ]
    }
   ],
   "source": [
    "print(\"MSG : Prediction\")\n",
    "#####################################################\n",
    "## Try to test and evaluate your model ##############\n",
    "## ex. test_x = [\"555+175\", \"860+7  \", \"340+29 \"]\n",
    "## ex. test_y = [\"730 \", \"867 \", \"369 \"] \n",
    "#####################################################\n",
    "#####################################################\n",
    "correct_ct = 0\n",
    "accuracy = 0\n",
    "for i in range(len(test_x)):\n",
    "    ind = np.random.randint(0, len(test_x))\n",
    "    rowx, rowy = test_x[np.array([ind])], test_y[np.array([ind])]\n",
    "    preds = model.predict_classes(rowx, verbose=0)\n",
    "    q = ctable.decode(rowx[0])\n",
    "    correct = ctable.decode(rowy[0])\n",
    "    guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        correct_ct = correct_ct + 1\n",
    "    else: \n",
    "        if i < 1000:\n",
    "            print(i, ' Q', q[::-1] if REVERSE else q, end=' ')\n",
    "            print('T', correct, end=' ')\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "            print(guess)\n",
    "accuracy = correct_ct/len(test_x)\n",
    "print('accu:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accu: 0.96505\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
