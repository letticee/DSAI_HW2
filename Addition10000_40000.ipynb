{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 40000\n",
    "DIGITS = 3\n",
    "REVERSE = False\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789+ '\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '+',\n",
       " 2: '0',\n",
       " 3: '1',\n",
       " 4: '2',\n",
       " 5: '3',\n",
       " 6: '4',\n",
       " 7: '5',\n",
       " 8: '6',\n",
       " 9: '7',\n",
       " 10: '8',\n",
       " 11: '9'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctable.indices_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 40000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['279+847', '2+171  ', '27+5   ', '3+58   ', '288+8  '] ['1126', '173 ', '32  ', '61  ', '296 ']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5], expected[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(expected), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(9000, 7, 12)\n",
      "(9000, 4, 12)\n",
      "Validation Data:\n",
      "(1000, 7, 12)\n",
      "(1000, 4, 12)\n",
      "Testing Data:\n",
      "(30000, 7, 12)\n",
      "(30000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# train_test_split\n",
    "train_x = x[:10000]\n",
    "train_y = y[:10000]\n",
    "test_x = x[10000:]\n",
    "test_y = y[10000:]\n",
    "\n",
    "split_at = len(train_x) - len(train_x) // 10\n",
    "(x_train, x_val) = train_x[:split_at], train_x[split_at:]\n",
    "(y_train, y_val) = train_y[:split_at], train_y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  [[[False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False  True False False False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]\n",
      "  [False False False False False False False  True False False False\n",
      "   False]\n",
      "  [False False False  True False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]\n",
      "  [False False False  True False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False False False  True False False False False\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False False  True False False False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]] \n",
      "\n",
      " label:  [[[False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False False False False False False  True False\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False False False False False False False False\n",
      "    True]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False False False  True False False False False\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False  True False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"input: \", x_train[:3], '\\n\\n', \"label: \", y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\SCREAM\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "############################################\n",
    "##### Build your own model here ############\n",
    "############################################\n",
    "model = Sequential()\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "for _ in range(LAYERS):\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SCREAM\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "9000/9000 [==============================] - 3s 350us/step - loss: 2.1175 - acc: 0.2669 - val_loss: 1.8920 - val_acc: 0.3380\n",
      "Epoch 2/200\n",
      "9000/9000 [==============================] - 1s 129us/step - loss: 1.8560 - acc: 0.3343 - val_loss: 1.8366 - val_acc: 0.3450\n",
      "Epoch 3/200\n",
      "9000/9000 [==============================] - 1s 138us/step - loss: 1.8313 - acc: 0.3424 - val_loss: 1.8221 - val_acc: 0.3500 0s - loss: 1.8356 - a\n",
      "Epoch 4/200\n",
      "9000/9000 [==============================] - 1s 130us/step - loss: 1.8018 - acc: 0.3470 - val_loss: 1.7944 - val_acc: 0.3462\n",
      "Epoch 5/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 1.7895 - acc: 0.3461 - val_loss: 1.7885 - val_acc: 0.3472\n",
      "Epoch 6/200\n",
      "9000/9000 [==============================] - 1s 132us/step - loss: 1.7759 - acc: 0.3477 - val_loss: 1.7714 - val_acc: 0.3502\n",
      "Epoch 7/200\n",
      "9000/9000 [==============================] - 1s 129us/step - loss: 1.7554 - acc: 0.3529 - val_loss: 1.7573 - val_acc: 0.3600\n",
      "Epoch 8/200\n",
      "9000/9000 [==============================] - 1s 133us/step - loss: 1.7379 - acc: 0.3594 - val_loss: 1.7336 - val_acc: 0.3683\n",
      "Epoch 9/200\n",
      "9000/9000 [==============================] - 1s 128us/step - loss: 1.7129 - acc: 0.3719 - val_loss: 1.7067 - val_acc: 0.3750\n",
      "Epoch 10/200\n",
      "9000/9000 [==============================] - 1s 127us/step - loss: 1.6916 - acc: 0.3758 - val_loss: 1.7254 - val_acc: 0.3780\n",
      "Epoch 11/200\n",
      "9000/9000 [==============================] - 1s 132us/step - loss: 1.6673 - acc: 0.3834 - val_loss: 1.6557 - val_acc: 0.3848\n",
      "Epoch 12/200\n",
      "9000/9000 [==============================] - 1s 130us/step - loss: 1.6281 - acc: 0.3941 - val_loss: 1.6333 - val_acc: 0.3917\n",
      "Epoch 13/200\n",
      "9000/9000 [==============================] - 1s 129us/step - loss: 1.5969 - acc: 0.4052 - val_loss: 1.5920 - val_acc: 0.4078\n",
      "Epoch 14/200\n",
      "9000/9000 [==============================] - 1s 130us/step - loss: 1.5671 - acc: 0.4168 - val_loss: 1.5801 - val_acc: 0.4073\n",
      "Epoch 15/200\n",
      "9000/9000 [==============================] - 1s 129us/step - loss: 1.5423 - acc: 0.4242 - val_loss: 1.5622 - val_acc: 0.4105\n",
      "Epoch 16/200\n",
      "9000/9000 [==============================] - 1s 132us/step - loss: 1.5223 - acc: 0.4310 - val_loss: 1.5318 - val_acc: 0.4250\n",
      "Epoch 17/200\n",
      "9000/9000 [==============================] - 1s 129us/step - loss: 1.4988 - acc: 0.4397 - val_loss: 1.5039 - val_acc: 0.4360\n",
      "Epoch 18/200\n",
      "9000/9000 [==============================] - 1s 135us/step - loss: 1.4719 - acc: 0.4534 - val_loss: 1.4914 - val_acc: 0.4460\n",
      "Epoch 19/200\n",
      "9000/9000 [==============================] - 1s 138us/step - loss: 1.4454 - acc: 0.4628 - val_loss: 1.4577 - val_acc: 0.4575\n",
      "Epoch 20/200\n",
      "9000/9000 [==============================] - 1s 130us/step - loss: 1.4203 - acc: 0.4762 - val_loss: 1.4441 - val_acc: 0.4585\n",
      "Epoch 21/200\n",
      "9000/9000 [==============================] - 1s 129us/step - loss: 1.3956 - acc: 0.4870 - val_loss: 1.4119 - val_acc: 0.4808\n",
      "Epoch 22/200\n",
      "9000/9000 [==============================] - 1s 131us/step - loss: 1.3565 - acc: 0.5038 - val_loss: 1.3979 - val_acc: 0.4848\n",
      "Epoch 23/200\n",
      "9000/9000 [==============================] - 1s 130us/step - loss: 1.3218 - acc: 0.5179 - val_loss: 1.3417 - val_acc: 0.5043\n",
      "Epoch 24/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 1.2884 - acc: 0.5303 - val_loss: 1.3129 - val_acc: 0.5175\n",
      "Epoch 25/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 1.2576 - acc: 0.5412 - val_loss: 1.2958 - val_acc: 0.5192\n",
      "Epoch 26/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 1.2309 - acc: 0.5493 - val_loss: 1.2744 - val_acc: 0.5255\n",
      "Epoch 27/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 1.2011 - acc: 0.5584 - val_loss: 1.2504 - val_acc: 0.5370\n",
      "Epoch 28/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 1.1823 - acc: 0.5676 - val_loss: 1.2329 - val_acc: 0.5400\n",
      "Epoch 29/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 1.1551 - acc: 0.5768 - val_loss: 1.2102 - val_acc: 0.5453\n",
      "Epoch 30/200\n",
      "9000/9000 [==============================] - 1s 152us/step - loss: 1.1230 - acc: 0.5884 - val_loss: 1.1841 - val_acc: 0.5613\n",
      "Epoch 31/200\n",
      "9000/9000 [==============================] - 1s 165us/step - loss: 1.1048 - acc: 0.5965 - val_loss: 1.1748 - val_acc: 0.5625\n",
      "Epoch 32/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 1.0753 - acc: 0.6059 - val_loss: 1.1614 - val_acc: 0.5698\n",
      "Epoch 33/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 1.0500 - acc: 0.6175 - val_loss: 1.1298 - val_acc: 0.5832\n",
      "Epoch 34/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 1.0276 - acc: 0.6246 - val_loss: 1.1232 - val_acc: 0.5763\n",
      "Epoch 35/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 1.0007 - acc: 0.6361 - val_loss: 1.0997 - val_acc: 0.5905\n",
      "Epoch 36/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 0.9815 - acc: 0.6427 - val_loss: 1.0859 - val_acc: 0.5927\n",
      "Epoch 37/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 0.9532 - acc: 0.6523 - val_loss: 1.0595 - val_acc: 0.6027\n",
      "Epoch 38/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 0.9210 - acc: 0.6648 - val_loss: 1.0341 - val_acc: 0.6145\n",
      "Epoch 39/200\n",
      "9000/9000 [==============================] - 1s 150us/step - loss: 0.8939 - acc: 0.6774 - val_loss: 1.0362 - val_acc: 0.6013\n",
      "Epoch 40/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 0.8731 - acc: 0.6799 - val_loss: 1.0036 - val_acc: 0.6098\n",
      "Epoch 41/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 0.8396 - acc: 0.6950 - val_loss: 0.9779 - val_acc: 0.6223\n",
      "Epoch 42/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 0.8119 - acc: 0.7083 - val_loss: 0.9753 - val_acc: 0.6208\n",
      "Epoch 43/200\n",
      "9000/9000 [==============================] - 1s 160us/step - loss: 0.7836 - acc: 0.7172 - val_loss: 0.9293 - val_acc: 0.6400\n",
      "Epoch 44/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 0.7563 - acc: 0.7266 - val_loss: 0.9061 - val_acc: 0.6490\n",
      "Epoch 45/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 0.7300 - acc: 0.7373 - val_loss: 0.8777 - val_acc: 0.6570\n",
      "Epoch 46/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 0.6960 - acc: 0.7512 - val_loss: 0.8591 - val_acc: 0.6600\n",
      "Epoch 47/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 0.6734 - acc: 0.7590 - val_loss: 0.8403 - val_acc: 0.6645\n",
      "Epoch 48/200\n",
      "9000/9000 [==============================] - 1s 153us/step - loss: 0.6486 - acc: 0.7709 - val_loss: 0.8260 - val_acc: 0.6763\n",
      "Epoch 49/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 0.6277 - acc: 0.7805 - val_loss: 0.8067 - val_acc: 0.6793\n",
      "Epoch 50/200\n",
      "9000/9000 [==============================] - 1s 150us/step - loss: 0.5982 - acc: 0.7936 - val_loss: 0.7829 - val_acc: 0.6878\n",
      "Epoch 51/200\n",
      "9000/9000 [==============================] - 1s 146us/step - loss: 0.5806 - acc: 0.7982 - val_loss: 0.7596 - val_acc: 0.6985\n",
      "Epoch 52/200\n",
      "9000/9000 [==============================] - 1s 146us/step - loss: 0.5548 - acc: 0.8115 - val_loss: 0.7691 - val_acc: 0.6950\n",
      "Epoch 53/200\n",
      "9000/9000 [==============================] - 1s 145us/step - loss: 0.5409 - acc: 0.8169 - val_loss: 0.7415 - val_acc: 0.7072\n",
      "Epoch 54/200\n",
      "9000/9000 [==============================] - 1s 145us/step - loss: 0.5124 - acc: 0.8311 - val_loss: 0.7217 - val_acc: 0.7140\n",
      "Epoch 55/200\n",
      "9000/9000 [==============================] - 1s 157us/step - loss: 0.4978 - acc: 0.8366 - val_loss: 0.7026 - val_acc: 0.7275\n",
      "Epoch 56/200\n",
      "9000/9000 [==============================] - 1s 145us/step - loss: 0.4800 - acc: 0.8423 - val_loss: 0.6864 - val_acc: 0.7340\n",
      "Epoch 57/200\n",
      "9000/9000 [==============================] - 1s 146us/step - loss: 0.4618 - acc: 0.8519 - val_loss: 0.6823 - val_acc: 0.7328\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.4436 - acc: 0.8619 - val_loss: 0.6732 - val_acc: 0.7378\n",
      "Epoch 59/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.4267 - acc: 0.8688 - val_loss: 0.6585 - val_acc: 0.7468\n",
      "Epoch 60/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.4132 - acc: 0.8722 - val_loss: 0.6466 - val_acc: 0.7460\n",
      "Epoch 61/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.3959 - acc: 0.8810 - val_loss: 0.6372 - val_acc: 0.7465\n",
      "Epoch 62/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.3816 - acc: 0.8874 - val_loss: 0.6371 - val_acc: 0.7532\n",
      "Epoch 63/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.3708 - acc: 0.8925 - val_loss: 0.6170 - val_acc: 0.7565\n",
      "Epoch 64/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.3501 - acc: 0.9023 - val_loss: 0.6170 - val_acc: 0.7615\n",
      "Epoch 65/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.3403 - acc: 0.9042 - val_loss: 0.6120 - val_acc: 0.7593\n",
      "Epoch 66/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.3265 - acc: 0.9106 - val_loss: 0.5993 - val_acc: 0.7710\n",
      "Epoch 67/200\n",
      "9000/9000 [==============================] - 1s 152us/step - loss: 0.3140 - acc: 0.9162 - val_loss: 0.5826 - val_acc: 0.7772\n",
      "Epoch 68/200\n",
      "9000/9000 [==============================] - 1s 145us/step - loss: 0.3043 - acc: 0.9194 - val_loss: 0.5951 - val_acc: 0.7695\n",
      "Epoch 69/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.2935 - acc: 0.9230 - val_loss: 0.5911 - val_acc: 0.7680\n",
      "Epoch 70/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.2856 - acc: 0.9246 - val_loss: 0.5769 - val_acc: 0.7773\n",
      "Epoch 71/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.2715 - acc: 0.9319 - val_loss: 0.5775 - val_acc: 0.7757\n",
      "Epoch 72/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.2594 - acc: 0.9383 - val_loss: 0.5614 - val_acc: 0.7792\n",
      "Epoch 73/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.2503 - acc: 0.9415 - val_loss: 0.5669 - val_acc: 0.7798\n",
      "Epoch 74/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.2442 - acc: 0.9431 - val_loss: 0.5780 - val_acc: 0.7835\n",
      "Epoch 75/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.2379 - acc: 0.9434 - val_loss: 0.5575 - val_acc: 0.7862\n",
      "Epoch 76/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.2202 - acc: 0.9542 - val_loss: 0.5413 - val_acc: 0.7975\n",
      "Epoch 77/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.2183 - acc: 0.9516 - val_loss: 0.5513 - val_acc: 0.7853\n",
      "Epoch 78/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.2098 - acc: 0.9542 - val_loss: 0.5481 - val_acc: 0.7847\n",
      "Epoch 79/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.2008 - acc: 0.9582 - val_loss: 0.5434 - val_acc: 0.7928\n",
      "Epoch 80/200\n",
      "9000/9000 [==============================] - 1s 153us/step - loss: 0.1914 - acc: 0.9621 - val_loss: 0.5327 - val_acc: 0.7975\n",
      "Epoch 81/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.1834 - acc: 0.9647 - val_loss: 0.5307 - val_acc: 0.8003\n",
      "Epoch 82/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.1761 - acc: 0.9678 - val_loss: 0.5410 - val_acc: 0.7993\n",
      "Epoch 83/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.1693 - acc: 0.9699 - val_loss: 0.5319 - val_acc: 0.8028\n",
      "Epoch 84/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.1593 - acc: 0.9734 - val_loss: 0.5348 - val_acc: 0.7930\n",
      "Epoch 85/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.1552 - acc: 0.9747 - val_loss: 0.5298 - val_acc: 0.8007\n",
      "Epoch 86/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.1478 - acc: 0.9771 - val_loss: 0.5224 - val_acc: 0.8033\n",
      "Epoch 87/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.1410 - acc: 0.9795 - val_loss: 0.5266 - val_acc: 0.8063\n",
      "Epoch 88/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.1429 - acc: 0.9768 - val_loss: 0.5387 - val_acc: 0.8045\n",
      "Epoch 89/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.1400 - acc: 0.9781 - val_loss: 0.5866 - val_acc: 0.7885\n",
      "Epoch 90/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.1583 - acc: 0.9655 - val_loss: 0.5315 - val_acc: 0.8042\n",
      "Epoch 91/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.1278 - acc: 0.9816 - val_loss: 0.5398 - val_acc: 0.8073\n",
      "Epoch 92/200\n",
      "9000/9000 [==============================] - 1s 157us/step - loss: 0.1182 - acc: 0.9849 - val_loss: 0.5184 - val_acc: 0.8095\n",
      "Epoch 93/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.1082 - acc: 0.9889 - val_loss: 0.5210 - val_acc: 0.8120\n",
      "Epoch 94/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.1049 - acc: 0.9891 - val_loss: 0.5207 - val_acc: 0.8160\n",
      "Epoch 95/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0987 - acc: 0.9913 - val_loss: 0.5321 - val_acc: 0.8050\n",
      "Epoch 96/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0977 - acc: 0.9914 - val_loss: 0.5296 - val_acc: 0.8077\n",
      "Epoch 97/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0922 - acc: 0.9924 - val_loss: 0.5288 - val_acc: 0.8147\n",
      "Epoch 98/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0915 - acc: 0.9919 - val_loss: 0.5274 - val_acc: 0.8110\n",
      "Epoch 99/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0857 - acc: 0.9934 - val_loss: 0.5296 - val_acc: 0.8100\n",
      "Epoch 100/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0796 - acc: 0.9951 - val_loss: 0.5317 - val_acc: 0.8078\n",
      "Epoch 101/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0773 - acc: 0.9947 - val_loss: 0.5367 - val_acc: 0.8102\n",
      "Epoch 102/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0734 - acc: 0.9958 - val_loss: 0.5318 - val_acc: 0.8145\n",
      "Epoch 103/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0706 - acc: 0.9960 - val_loss: 0.5405 - val_acc: 0.8085\n",
      "Epoch 104/200\n",
      "9000/9000 [==============================] - 1s 152us/step - loss: 0.0664 - acc: 0.9972 - val_loss: 0.5428 - val_acc: 0.8090\n",
      "Epoch 105/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 0.0662 - acc: 0.9967 - val_loss: 0.5302 - val_acc: 0.8155\n",
      "Epoch 106/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0701 - acc: 0.9950 - val_loss: 0.5420 - val_acc: 0.8120\n",
      "Epoch 107/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0641 - acc: 0.9963 - val_loss: 0.5504 - val_acc: 0.8085\n",
      "Epoch 108/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0584 - acc: 0.9976 - val_loss: 0.5444 - val_acc: 0.8140\n",
      "Epoch 109/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0549 - acc: 0.9984 - val_loss: 0.5536 - val_acc: 0.8165\n",
      "Epoch 110/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0526 - acc: 0.9985 - val_loss: 0.5577 - val_acc: 0.8158\n",
      "Epoch 111/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0491 - acc: 0.9988 - val_loss: 0.5460 - val_acc: 0.8165\n",
      "Epoch 112/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0470 - acc: 0.9990 - val_loss: 0.5558 - val_acc: 0.8147\n",
      "Epoch 113/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0463 - acc: 0.9990 - val_loss: 0.5572 - val_acc: 0.8170\n",
      "Epoch 114/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0448 - acc: 0.9990 - val_loss: 0.5603 - val_acc: 0.8158\n",
      "Epoch 115/200\n",
      "9000/9000 [==============================] - 1s 145us/step - loss: 0.0435 - acc: 0.9991 - val_loss: 0.5667 - val_acc: 0.8157\n",
      "Epoch 116/200\n",
      "9000/9000 [==============================] - 1s 147us/step - loss: 0.0416 - acc: 0.9993 - val_loss: 0.5659 - val_acc: 0.8153\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 1s 152us/step - loss: 0.0467 - acc: 0.9966 - val_loss: 0.6277 - val_acc: 0.7915\n",
      "Epoch 118/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.1494 - acc: 0.9534 - val_loss: 0.7215 - val_acc: 0.7785\n",
      "Epoch 119/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.1896 - acc: 0.9382 - val_loss: 0.6505 - val_acc: 0.7863\n",
      "Epoch 120/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0929 - acc: 0.9786 - val_loss: 0.5730 - val_acc: 0.8090\n",
      "Epoch 121/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0438 - acc: 0.9983 - val_loss: 0.5503 - val_acc: 0.8220\n",
      "Epoch 122/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0339 - acc: 0.9997 - val_loss: 0.5486 - val_acc: 0.8205\n",
      "Epoch 123/200\n",
      "9000/9000 [==============================] - 1s 147us/step - loss: 0.0306 - acc: 0.9998 - val_loss: 0.5547 - val_acc: 0.8200\n",
      "Epoch 124/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0285 - acc: 0.9999 - val_loss: 0.5590 - val_acc: 0.8210\n",
      "Epoch 125/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0268 - acc: 0.9999 - val_loss: 0.5590 - val_acc: 0.8200\n",
      "Epoch 126/200\n",
      "9000/9000 [==============================] - 1s 140us/step - loss: 0.0256 - acc: 0.9999 - val_loss: 0.5662 - val_acc: 0.8178\n",
      "Epoch 127/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.5686 - val_acc: 0.8177\n",
      "Epoch 128/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0235 - acc: 0.9999 - val_loss: 0.5703 - val_acc: 0.8175\n",
      "Epoch 129/200\n",
      "9000/9000 [==============================] - 1s 154us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.5798 - val_acc: 0.8183\n",
      "Epoch 130/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.5777 - val_acc: 0.8167\n",
      "Epoch 131/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.5840 - val_acc: 0.8165\n",
      "Epoch 132/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.5870 - val_acc: 0.8172\n",
      "Epoch 133/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.8177\n",
      "Epoch 134/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.8208\n",
      "Epoch 135/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6055 - val_acc: 0.8132\n",
      "Epoch 136/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.5977 - val_acc: 0.8155\n",
      "Epoch 137/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6079 - val_acc: 0.8170\n",
      "Epoch 138/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.6108 - val_acc: 0.8165\n",
      "Epoch 139/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.6136 - val_acc: 0.8133\n",
      "Epoch 140/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.6206 - val_acc: 0.8142\n",
      "Epoch 141/200\n",
      "9000/9000 [==============================] - 1s 149us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.6215 - val_acc: 0.8160\n",
      "Epoch 142/200\n",
      "9000/9000 [==============================] - 1s 153us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.6185 - val_acc: 0.8165\n",
      "Epoch 143/200\n",
      "9000/9000 [==============================] - 1s 145us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.6273 - val_acc: 0.8158\n",
      "Epoch 144/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.6298 - val_acc: 0.8155\n",
      "Epoch 145/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.6322 - val_acc: 0.8177\n",
      "Epoch 146/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.8135\n",
      "Epoch 147/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.6430 - val_acc: 0.8157\n",
      "Epoch 148/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.6471 - val_acc: 0.8145\n",
      "Epoch 149/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.6503 - val_acc: 0.8098\n",
      "Epoch 150/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.8157\n",
      "Epoch 151/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.6589 - val_acc: 0.8127\n",
      "Epoch 152/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.6540 - val_acc: 0.8125\n",
      "Epoch 153/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.6588 - val_acc: 0.8155\n",
      "Epoch 154/200\n",
      "9000/9000 [==============================] - 1s 155us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.6594 - val_acc: 0.8200\n",
      "Epoch 155/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.8142\n",
      "Epoch 156/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.8165\n",
      "Epoch 157/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.6730 - val_acc: 0.8163\n",
      "Epoch 158/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.6820 - val_acc: 0.8142\n",
      "Epoch 159/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.6843 - val_acc: 0.8123\n",
      "Epoch 160/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.6964 - val_acc: 0.8097\n",
      "Epoch 161/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0078 - acc: 0.9998 - val_loss: 0.7716 - val_acc: 0.7928\n",
      "Epoch 162/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.3846 - acc: 0.8818 - val_loss: 0.8431 - val_acc: 0.7640\n",
      "Epoch 163/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.1529 - acc: 0.9482 - val_loss: 0.6701 - val_acc: 0.8010\n",
      "Epoch 164/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0418 - acc: 0.9912 - val_loss: 0.6301 - val_acc: 0.8135\n",
      "Epoch 165/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0179 - acc: 0.9995 - val_loss: 0.6080 - val_acc: 0.8218\n",
      "Epoch 166/200\n",
      "9000/9000 [==============================] - 1s 154us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.6126 - val_acc: 0.8210\n",
      "Epoch 167/200\n",
      "9000/9000 [==============================] - 1s 145us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.8235\n",
      "Epoch 168/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.6146 - val_acc: 0.8233\n",
      "Epoch 169/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.6217 - val_acc: 0.8213\n",
      "Epoch 170/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.6218 - val_acc: 0.8235\n",
      "Epoch 171/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.6257 - val_acc: 0.8260\n",
      "Epoch 172/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.6274 - val_acc: 0.8232\n",
      "Epoch 173/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.6327 - val_acc: 0.8240\n",
      "Epoch 174/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 0.8232\n",
      "Epoch 175/200\n",
      "9000/9000 [==============================] - 1s 145us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.6389 - val_acc: 0.8190\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.6422 - val_acc: 0.8218\n",
      "Epoch 177/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.6418 - val_acc: 0.8203\n",
      "Epoch 178/200\n",
      "9000/9000 [==============================] - 1s 147us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.8218\n",
      "Epoch 179/200\n",
      "9000/9000 [==============================] - 1s 150us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.6499 - val_acc: 0.8215\n",
      "Epoch 180/200\n",
      "9000/9000 [==============================] - 1s 140us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.6502 - val_acc: 0.8230\n",
      "Epoch 181/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.6568 - val_acc: 0.8220\n",
      "Epoch 182/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.6590 - val_acc: 0.8210\n",
      "Epoch 183/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.6604 - val_acc: 0.8228\n",
      "Epoch 184/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.6648 - val_acc: 0.8205\n",
      "Epoch 185/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.6656 - val_acc: 0.8205\n",
      "Epoch 186/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.8200\n",
      "Epoch 187/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.6716 - val_acc: 0.8200\n",
      "Epoch 188/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.6742 - val_acc: 0.8212\n",
      "Epoch 189/200\n",
      "9000/9000 [==============================] - 1s 144us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.6780 - val_acc: 0.8182\n",
      "Epoch 190/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.6808 - val_acc: 0.8215\n",
      "Epoch 191/200\n",
      "9000/9000 [==============================] - 1s 156us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6813 - val_acc: 0.8217\n",
      "Epoch 192/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.6864 - val_acc: 0.8190\n",
      "Epoch 193/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6913 - val_acc: 0.8173\n",
      "Epoch 194/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.6894 - val_acc: 0.8200\n",
      "Epoch 195/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6913 - val_acc: 0.8187\n",
      "Epoch 196/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6969 - val_acc: 0.8205\n",
      "Epoch 197/200\n",
      "9000/9000 [==============================] - 1s 141us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6996 - val_acc: 0.8192\n",
      "Epoch 198/200\n",
      "9000/9000 [==============================] - 1s 148us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6999 - val_acc: 0.81971s - loss: 0.\n",
      "Epoch 199/200\n",
      "9000/9000 [==============================] - 1s 143us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7060 - val_acc: 0.8183\n",
      "Epoch 200/200\n",
      "9000/9000 [==============================] - 1s 142us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7097 - val_acc: 0.8200\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training = model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=200,\n",
    "              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'3 digits add')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc = training.history['val_acc']\n",
    "acc = training.history['acc']\n",
    "plt.figure()\n",
    "plt.plot(val_acc, label = 'val_acc')\n",
    "plt.plot(acc, label = 'acc')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('3 digits add')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSG : Prediction\n",
      "1  Q 459+21  T 480  \u001b[91m\u001b[0m 490 \n",
      "2  Q 974+655 T 1629 \u001b[91m\u001b[0m 1639\n",
      "6  Q 157+47  T 204  \u001b[91m\u001b[0m 184 \n",
      "8  Q 67+502  T 569  \u001b[91m\u001b[0m 559 \n",
      "13  Q 426+741 T 1167 \u001b[91m\u001b[0m 1186\n",
      "14  Q 376+408 T 784  \u001b[91m\u001b[0m 775 \n",
      "15  Q 64+72   T 136  \u001b[91m\u001b[0m 135 \n",
      "21  Q 773+778 T 1551 \u001b[91m\u001b[0m 1552\n",
      "27  Q 79+110  T 189  \u001b[91m\u001b[0m 199 \n",
      "30  Q 764+94  T 858  \u001b[91m\u001b[0m 848 \n",
      "32  Q 422+137 T 559  \u001b[91m\u001b[0m 579 \n",
      "33  Q 259+191 T 450  \u001b[91m\u001b[0m 439 \n",
      "34  Q 956+702 T 1658 \u001b[91m\u001b[0m 1659\n",
      "40  Q 891+206 T 1097 \u001b[91m\u001b[0m 1095\n",
      "43  Q 80+883  T 963  \u001b[91m\u001b[0m 964 \n",
      "44  Q 562+9   T 571  \u001b[91m\u001b[0m 572 \n",
      "45  Q 771+722 T 1493 \u001b[91m\u001b[0m 1572\n",
      "47  Q 13+443  T 456  \u001b[91m\u001b[0m 446 \n",
      "48  Q 35+962  T 997  \u001b[91m\u001b[0m 987 \n",
      "49  Q 93+161  T 254  \u001b[91m\u001b[0m 234 \n",
      "50  Q 752+593 T 1345 \u001b[91m\u001b[0m 1315\n",
      "51  Q 486+611 T 1097 \u001b[91m\u001b[0m 1197\n",
      "55  Q 203+319 T 522  \u001b[91m\u001b[0m 433 \n",
      "56  Q 973+97  T 1070 \u001b[91m\u001b[0m 1021\n",
      "57  Q 90+456  T 546  \u001b[91m\u001b[0m 556 \n",
      "59  Q 597+695 T 1292 \u001b[91m\u001b[0m 1272\n",
      "60  Q 26+417  T 443  \u001b[91m\u001b[0m 352 \n",
      "62  Q 436+110 T 546  \u001b[91m\u001b[0m 456 \n",
      "64  Q 322+814 T 1136 \u001b[91m\u001b[0m 1146\n",
      "66  Q 2+655   T 657  \u001b[91m\u001b[0m 656 \n",
      "67  Q 885+38  T 923  \u001b[91m\u001b[0m 922 \n",
      "68  Q 46+260  T 306  \u001b[91m\u001b[0m 307 \n",
      "71  Q 558+35  T 593  \u001b[91m\u001b[0m 503 \n",
      "72  Q 6+525   T 531  \u001b[91m\u001b[0m 521 \n",
      "73  Q 80+926  T 1006 \u001b[91m\u001b[0m 906 \n",
      "74  Q 16+17   T 33   \u001b[91m\u001b[0m 3   \n",
      "75  Q 56+879  T 935  \u001b[91m\u001b[0m 925 \n",
      "76  Q 0+212   T 212  \u001b[91m\u001b[0m 222 \n",
      "78  Q 737+568 T 1305 \u001b[91m\u001b[0m 1285\n",
      "81  Q 760+856 T 1616 \u001b[91m\u001b[0m 1636\n",
      "86  Q 268+68  T 336  \u001b[91m\u001b[0m 346 \n",
      "88  Q 610+87  T 697  \u001b[91m\u001b[0m 698 \n",
      "90  Q 979+596 T 1575 \u001b[91m\u001b[0m 1585\n",
      "91  Q 69+994  T 1063 \u001b[91m\u001b[0m 1064\n",
      "92  Q 46+39   T 85   \u001b[91m\u001b[0m 76  \n",
      "94  Q 639+33  T 672  \u001b[91m\u001b[0m 662 \n",
      "97  Q 450+79  T 529  \u001b[91m\u001b[0m 538 \n",
      "100  Q 74+485  T 559  \u001b[91m\u001b[0m 550 \n",
      "102  Q 868+51  T 919  \u001b[91m\u001b[0m 929 \n",
      "105  Q 231+14  T 245  \u001b[91m\u001b[0m 255 \n",
      "107  Q 168+66  T 234  \u001b[91m\u001b[0m 244 \n",
      "108  Q 851+68  T 919  \u001b[91m\u001b[0m 929 \n",
      "111  Q 946+26  T 972  \u001b[91m\u001b[0m 962 \n",
      "112  Q 561+482 T 1043 \u001b[91m\u001b[0m 1012\n",
      "114  Q 871+143 T 1014 \u001b[91m\u001b[0m 1024\n",
      "115  Q 961+933 T 1894 \u001b[91m\u001b[0m 1863\n",
      "116  Q 477+856 T 1333 \u001b[91m\u001b[0m 1314\n",
      "117  Q 561+41  T 602  \u001b[91m\u001b[0m 601 \n",
      "119  Q 15+741  T 756  \u001b[91m\u001b[0m 746 \n",
      "120  Q 11+770  T 781  \u001b[91m\u001b[0m 771 \n",
      "123  Q 274+514 T 788  \u001b[91m\u001b[0m 778 \n",
      "124  Q 451+87  T 538  \u001b[91m\u001b[0m 539 \n",
      "125  Q 48+77   T 125  \u001b[91m\u001b[0m 115 \n",
      "127  Q 48+91   T 139  \u001b[91m\u001b[0m 130 \n",
      "130  Q 1+708   T 709  \u001b[91m\u001b[0m 708 \n",
      "132  Q 3+997   T 1000 \u001b[91m\u001b[0m 990 \n",
      "134  Q 20+521  T 541  \u001b[91m\u001b[0m 551 \n",
      "135  Q 347+200 T 547  \u001b[91m\u001b[0m 647 \n",
      "136  Q 726+272 T 998  \u001b[91m\u001b[0m 989 \n",
      "141  Q 368+443 T 811  \u001b[91m\u001b[0m 721 \n",
      "142  Q 506+271 T 777  \u001b[91m\u001b[0m 786 \n",
      "146  Q 42+6    T 48   \u001b[91m\u001b[0m 49  \n",
      "150  Q 192+406 T 598  \u001b[91m\u001b[0m 587 \n",
      "151  Q 46+327  T 373  \u001b[91m\u001b[0m 363 \n",
      "156  Q 68+869  T 937  \u001b[91m\u001b[0m 928 \n",
      "157  Q 201+152 T 353  \u001b[91m\u001b[0m 224 \n",
      "158  Q 38+782  T 820  \u001b[91m\u001b[0m 811 \n",
      "162  Q 389+736 T 1125 \u001b[91m\u001b[0m 1164\n",
      "164  Q 24+708  T 732  \u001b[91m\u001b[0m 722 \n",
      "171  Q 728+642 T 1370 \u001b[91m\u001b[0m 1360\n",
      "175  Q 39+195  T 234  \u001b[91m\u001b[0m 245 \n",
      "177  Q 3+819   T 822  \u001b[91m\u001b[0m 823 \n",
      "179  Q 996+72  T 1068 \u001b[91m\u001b[0m 1067\n",
      "181  Q 48+8    T 56   \u001b[91m\u001b[0m 57  \n",
      "182  Q 395+617 T 1012 \u001b[91m\u001b[0m 9042\n",
      "185  Q 677+21  T 698  \u001b[91m\u001b[0m 798 \n",
      "186  Q 14+56   T 70   \u001b[91m\u001b[0m 69  \n",
      "187  Q 265+0   T 265  \u001b[91m\u001b[0m 264 \n",
      "188  Q 86+398  T 484  \u001b[91m\u001b[0m 474 \n",
      "190  Q 675+243 T 918  \u001b[91m\u001b[0m 908 \n",
      "191  Q 51+370  T 421  \u001b[91m\u001b[0m 411 \n",
      "192  Q 567+386 T 953  \u001b[91m\u001b[0m 944 \n",
      "195  Q 239+610 T 849  \u001b[91m\u001b[0m 859 \n",
      "196  Q 711+550 T 1261 \u001b[91m\u001b[0m 1251\n",
      "198  Q 56+863  T 919  \u001b[91m\u001b[0m 929 \n",
      "201  Q 302+50  T 352  \u001b[91m\u001b[0m 322 \n",
      "202  Q 680+3   T 683  \u001b[91m\u001b[0m 684 \n",
      "203  Q 264+681 T 945  \u001b[91m\u001b[0m 944 \n",
      "205  Q 377+520 T 897  \u001b[91m\u001b[0m 898 \n",
      "206  Q 667+862 T 1529 \u001b[91m\u001b[0m 1530\n",
      "208  Q 498+31  T 529  \u001b[91m\u001b[0m 530 \n",
      "210  Q 55+207  T 262  \u001b[91m\u001b[0m 261 \n",
      "211  Q 70+610  T 680  \u001b[91m\u001b[0m 690 \n",
      "213  Q 49+898  T 947  \u001b[91m\u001b[0m 938 \n",
      "214  Q 973+62  T 1035 \u001b[91m\u001b[0m 1025\n",
      "216  Q 960+19  T 979  \u001b[91m\u001b[0m 989 \n",
      "217  Q 34+13   T 47   \u001b[91m\u001b[0m 57  \n",
      "218  Q 519+0   T 519  \u001b[91m\u001b[0m 529 \n",
      "219  Q 1+356   T 357  \u001b[91m\u001b[0m 358 \n",
      "224  Q 7+343   T 350  \u001b[91m\u001b[0m 340 \n",
      "226  Q 989+348 T 1337 \u001b[91m\u001b[0m 1346\n",
      "227  Q 742+7   T 749  \u001b[91m\u001b[0m 759 \n",
      "228  Q 35+22   T 57   \u001b[91m\u001b[0m 47  \n",
      "230  Q 360+974 T 1334 \u001b[91m\u001b[0m 1347\n",
      "232  Q 419+210 T 629  \u001b[91m\u001b[0m 630 \n",
      "233  Q 399+42  T 441  \u001b[91m\u001b[0m 542 \n",
      "235  Q 64+7    T 71   \u001b[91m\u001b[0m 72  \n",
      "237  Q 273+112 T 385  \u001b[91m\u001b[0m 394 \n",
      "238  Q 437+66  T 503  \u001b[91m\u001b[0m 514 \n",
      "239  Q 722+33  T 755  \u001b[91m\u001b[0m 765 \n",
      "240  Q 4+847   T 851  \u001b[91m\u001b[0m 852 \n",
      "241  Q 162+21  T 183  \u001b[91m\u001b[0m 173 \n",
      "243  Q 48+152  T 200  \u001b[91m\u001b[0m 290 \n",
      "245  Q 8+402   T 410  \u001b[91m\u001b[0m 400 \n",
      "246  Q 145+5   T 150  \u001b[91m\u001b[0m 151 \n",
      "247  Q 518+594 T 1112 \u001b[91m\u001b[0m 1040\n",
      "248  Q 15+834  T 849  \u001b[91m\u001b[0m 858 \n",
      "249  Q 12+687  T 699  \u001b[91m\u001b[0m 609 \n",
      "250  Q 717+415 T 1132 \u001b[91m\u001b[0m 1122\n",
      "252  Q 31+348  T 379  \u001b[91m\u001b[0m 389 \n",
      "253  Q 417+572 T 989  \u001b[91m\u001b[0m 909 \n",
      "254  Q 575+31  T 606  \u001b[91m\u001b[0m 695 \n",
      "255  Q 3+781   T 784  \u001b[91m\u001b[0m 774 \n",
      "256  Q 53+3    T 56   \u001b[91m\u001b[0m 55  \n",
      "257  Q 529+930 T 1459 \u001b[91m\u001b[0m 1449\n",
      "258  Q 348+168 T 516  \u001b[91m\u001b[0m 526 \n",
      "261  Q 150+498 T 648  \u001b[91m\u001b[0m 609 \n",
      "262  Q 810+61  T 871  \u001b[91m\u001b[0m 881 \n",
      "264  Q 45+971  T 1016 \u001b[91m\u001b[0m 1006\n",
      "265  Q 90+310  T 400  \u001b[91m\u001b[0m 401 \n",
      "267  Q 81+394  T 475  \u001b[91m\u001b[0m 474 \n",
      "270  Q 3+198   T 201  \u001b[91m\u001b[0m 101 \n",
      "271  Q 188+844 T 1032 \u001b[91m\u001b[0m 1022\n",
      "277  Q 83+89   T 172  \u001b[91m\u001b[0m 171 \n",
      "278  Q 984+102 T 1086 \u001b[91m\u001b[0m 1027\n",
      "279  Q 757+12  T 769  \u001b[91m\u001b[0m 778 \n",
      "280  Q 34+253  T 287  \u001b[91m\u001b[0m 277 \n",
      "283  Q 606+260 T 866  \u001b[91m\u001b[0m 876 \n",
      "287  Q 77+914  T 991  \u001b[91m\u001b[0m 1002\n",
      "289  Q 91+50   T 141  \u001b[91m\u001b[0m 142 \n",
      "291  Q 761+52  T 813  \u001b[91m\u001b[0m 823 \n",
      "293  Q 710+0   T 710  \u001b[91m\u001b[0m 711 \n",
      "294  Q 966+169 T 1135 \u001b[91m\u001b[0m 1155\n",
      "297  Q 32+415  T 447  \u001b[91m\u001b[0m 437 \n",
      "298  Q 212+906 T 1118 \u001b[91m\u001b[0m 1117\n",
      "299  Q 450+412 T 862  \u001b[91m\u001b[0m 852 \n",
      "301  Q 799+398 T 1197 \u001b[91m\u001b[0m 1188\n",
      "302  Q 54+495  T 549  \u001b[91m\u001b[0m 540 \n",
      "305  Q 635+2   T 637  \u001b[91m\u001b[0m 636 \n",
      "310  Q 466+880 T 1346 \u001b[91m\u001b[0m 1358\n",
      "311  Q 205+327 T 532  \u001b[91m\u001b[0m 531 \n",
      "312  Q 6+170   T 176  \u001b[91m\u001b[0m 177 \n",
      "314  Q 843+69  T 912  \u001b[91m\u001b[0m 922 \n",
      "316  Q 70+795  T 865  \u001b[91m\u001b[0m 855 \n",
      "317  Q 33+116  T 149  \u001b[91m\u001b[0m 159 \n",
      "318  Q 58+2    T 60   \u001b[91m\u001b[0m 59  \n",
      "320  Q 601+766 T 1367 \u001b[91m\u001b[0m 1377\n",
      "324  Q 809+895 T 1704 \u001b[91m\u001b[0m 1705\n",
      "326  Q 6+995   T 1001 \u001b[91m\u001b[0m 1002\n",
      "328  Q 502+1   T 503  \u001b[91m\u001b[0m 504 \n",
      "329  Q 97+951  T 1048 \u001b[91m\u001b[0m 1047\n",
      "331  Q 751+8   T 759  \u001b[91m\u001b[0m 769 \n",
      "333  Q 846+237 T 1083 \u001b[91m\u001b[0m 1093\n",
      "334  Q 741+928 T 1669 \u001b[91m\u001b[0m 1621\n",
      "335  Q 947+34  T 981  \u001b[91m\u001b[0m 972 \n",
      "336  Q 812+5   T 817  \u001b[91m\u001b[0m 818 \n",
      "337  Q 749+720 T 1469 \u001b[91m\u001b[0m 1560\n",
      "338  Q 495+47  T 542  \u001b[91m\u001b[0m 531 \n",
      "340  Q 991+812 T 1803 \u001b[91m\u001b[0m 1804\n",
      "341  Q 37+190  T 227  \u001b[91m\u001b[0m 207 \n",
      "342  Q 391+278 T 669  \u001b[91m\u001b[0m 678 \n",
      "345  Q 1+51    T 52   \u001b[91m\u001b[0m 51  \n",
      "346  Q 71+16   T 87   \u001b[91m\u001b[0m 88  \n",
      "347  Q 195+317 T 512  \u001b[91m\u001b[0m 532 \n",
      "349  Q 837+72  T 909  \u001b[91m\u001b[0m 919 \n",
      "353  Q 87+80   T 167  \u001b[91m\u001b[0m 168 \n",
      "354  Q 834+717 T 1551 \u001b[91m\u001b[0m 1541\n",
      "355  Q 116+654 T 770  \u001b[91m\u001b[0m 779 \n",
      "356  Q 338+76  T 414  \u001b[91m\u001b[0m 424 \n",
      "357  Q 31+580  T 611  \u001b[91m\u001b[0m 811 \n",
      "358  Q 346+126 T 472  \u001b[91m\u001b[0m 452 \n",
      "362  Q 9+741   T 750  \u001b[91m\u001b[0m 740 \n",
      "363  Q 575+31  T 606  \u001b[91m\u001b[0m 695 \n",
      "365  Q 783+62  T 845  \u001b[91m\u001b[0m 846 \n",
      "366  Q 593+8   T 601  \u001b[91m\u001b[0m 502 \n",
      "371  Q 598+56  T 654  \u001b[91m\u001b[0m 644 \n",
      "374  Q 692+8   T 700  \u001b[91m\u001b[0m 601 \n",
      "376  Q 889+37  T 926  \u001b[91m\u001b[0m 946 \n",
      "377  Q 558+157 T 715  \u001b[91m\u001b[0m 705 \n",
      "378  Q 611+537 T 1148 \u001b[91m\u001b[0m 1139\n",
      "379  Q 69+17   T 86   \u001b[91m\u001b[0m 77  \n",
      "381  Q 269+370 T 639  \u001b[91m\u001b[0m 638 \n",
      "383  Q 5+640   T 645  \u001b[91m\u001b[0m 646 \n",
      "384  Q 920+100 T 1020 \u001b[91m\u001b[0m 1011\n",
      "385  Q 504+352 T 856  \u001b[91m\u001b[0m 857 \n",
      "386  Q 92+434  T 526  \u001b[91m\u001b[0m 527 \n",
      "387  Q 5+503   T 508  \u001b[91m\u001b[0m 509 \n",
      "390  Q 402+0   T 402  \u001b[91m\u001b[0m 400 \n",
      "391  Q 158+575 T 733  \u001b[91m\u001b[0m 743 \n",
      "393  Q 15+635  T 650  \u001b[91m\u001b[0m 640 \n",
      "394  Q 988+56  T 1044 \u001b[91m\u001b[0m 1043\n",
      "397  Q 184+27  T 211  \u001b[91m\u001b[0m 200 \n",
      "399  Q 27+81   T 108  \u001b[91m\u001b[0m 999 \n",
      "400  Q 36+119  T 155  \u001b[91m\u001b[0m 165 \n",
      "401  Q 332+8   T 340  \u001b[91m\u001b[0m 330 \n",
      "402  Q 59+734  T 793  \u001b[91m\u001b[0m 783 \n",
      "404  Q 459+36  T 495  \u001b[91m\u001b[0m 505 \n",
      "406  Q 37+8    T 45   \u001b[91m\u001b[0m 42  \n",
      "408  Q 76+977  T 1053 \u001b[91m\u001b[0m 1042\n",
      "410  Q 661+30  T 691  \u001b[91m\u001b[0m 791 \n",
      "411  Q 651+316 T 967  \u001b[91m\u001b[0m 957 \n",
      "412  Q 135+460 T 595  \u001b[91m\u001b[0m 605 \n",
      "413  Q 229+598 T 827  \u001b[91m\u001b[0m 817 \n",
      "414  Q 302+51  T 353  \u001b[91m\u001b[0m 352 \n",
      "415  Q 9+49    T 58   \u001b[91m\u001b[0m 57  \n",
      "418  Q 16+439  T 455  \u001b[91m\u001b[0m 465 \n",
      "423  Q 332+5   T 337  \u001b[91m\u001b[0m 327 \n",
      "424  Q 316+619 T 935  \u001b[91m\u001b[0m 955 \n",
      "426  Q 9+483   T 492  \u001b[91m\u001b[0m 491 \n",
      "427  Q 350+963 T 1313 \u001b[91m\u001b[0m 1305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428  Q 61+34   T 95   \u001b[91m\u001b[0m 94  \n",
      "429  Q 32+942  T 974  \u001b[91m\u001b[0m 964 \n",
      "432  Q 354+28  T 382  \u001b[91m\u001b[0m 372 \n",
      "433  Q 324+97  T 421  \u001b[91m\u001b[0m 411 \n",
      "434  Q 65+817  T 882  \u001b[91m\u001b[0m 872 \n",
      "436  Q 49+639  T 688  \u001b[91m\u001b[0m 697 \n",
      "438  Q 78+950  T 1028 \u001b[91m\u001b[0m 1008\n",
      "440  Q 494+865 T 1359 \u001b[91m\u001b[0m 1379\n",
      "441  Q 16+402  T 418  \u001b[91m\u001b[0m 427 \n",
      "444  Q 936+695 T 1631 \u001b[91m\u001b[0m 1591\n",
      "445  Q 60+191  T 251  \u001b[91m\u001b[0m 231 \n",
      "446  Q 24+377  T 401  \u001b[91m\u001b[0m 301 \n",
      "449  Q 80+41   T 121  \u001b[91m\u001b[0m 120 \n",
      "453  Q 395+447 T 842  \u001b[91m\u001b[0m 832 \n",
      "454  Q 22+547  T 569  \u001b[91m\u001b[0m 579 \n",
      "456  Q 743+63  T 806  \u001b[91m\u001b[0m 706 \n",
      "457  Q 891+35  T 926  \u001b[91m\u001b[0m 906 \n",
      "458  Q 38+436  T 474  \u001b[91m\u001b[0m 464 \n",
      "459  Q 321+21  T 342  \u001b[91m\u001b[0m 351 \n",
      "461  Q 675+243 T 918  \u001b[91m\u001b[0m 908 \n",
      "462  Q 96+274  T 370  \u001b[91m\u001b[0m 360 \n",
      "463  Q 428+182 T 610  \u001b[91m\u001b[0m 500 \n",
      "466  Q 41+24   T 65   \u001b[91m\u001b[0m 66  \n",
      "470  Q 675+84  T 759  \u001b[91m\u001b[0m 768 \n",
      "475  Q 569+77  T 646  \u001b[91m\u001b[0m 636 \n",
      "476  Q 142+554 T 696  \u001b[91m\u001b[0m 606 \n",
      "477  Q 135+251 T 386  \u001b[91m\u001b[0m 376 \n",
      "478  Q 458+199 T 657  \u001b[91m\u001b[0m 647 \n",
      "479  Q 346+216 T 562  \u001b[91m\u001b[0m 452 \n",
      "482  Q 55+371  T 426  \u001b[91m\u001b[0m 427 \n",
      "484  Q 309+960 T 1269 \u001b[91m\u001b[0m 1268\n",
      "485  Q 679+808 T 1487 \u001b[91m\u001b[0m 1587\n",
      "486  Q 296+115 T 411  \u001b[91m\u001b[0m 412 \n",
      "487  Q 5+211   T 216  \u001b[91m\u001b[0m 217 \n",
      "488  Q 85+326  T 411  \u001b[91m\u001b[0m 401 \n",
      "489  Q 159+872 T 1031 \u001b[91m\u001b[0m 1021\n",
      "490  Q 542+38  T 580  \u001b[91m\u001b[0m 581 \n",
      "491  Q 374+65  T 439  \u001b[91m\u001b[0m 449 \n",
      "492  Q 36+170  T 206  \u001b[91m\u001b[0m 207 \n",
      "493  Q 61+507  T 568  \u001b[91m\u001b[0m 577 \n",
      "494  Q 906+59  T 965  \u001b[91m\u001b[0m 995 \n",
      "495  Q 465+9   T 474  \u001b[91m\u001b[0m 475 \n",
      "498  Q 23+697  T 720  \u001b[91m\u001b[0m 710 \n",
      "500  Q 771+558 T 1329 \u001b[91m\u001b[0m 1338\n",
      "502  Q 48+778  T 826  \u001b[91m\u001b[0m 816 \n",
      "505  Q 85+618  T 703  \u001b[91m\u001b[0m 713 \n",
      "507  Q 489+693 T 1182 \u001b[91m\u001b[0m 1073\n",
      "509  Q 969+501 T 1470 \u001b[91m\u001b[0m 1478\n",
      "512  Q 923+50  T 973  \u001b[91m\u001b[0m 953 \n",
      "515  Q 443+602 T 1045 \u001b[91m\u001b[0m 1044\n",
      "517  Q 921+739 T 1660 \u001b[91m\u001b[0m 1769\n",
      "518  Q 70+13   T 83   \u001b[91m\u001b[0m 93  \n",
      "519  Q 277+258 T 535  \u001b[91m\u001b[0m 524 \n",
      "520  Q 268+520 T 788  \u001b[91m\u001b[0m 780 \n",
      "522  Q 34+56   T 90   \u001b[91m\u001b[0m 99  \n",
      "524  Q 10+751  T 761  \u001b[91m\u001b[0m 771 \n",
      "528  Q 328+71  T 399  \u001b[91m\u001b[0m 409 \n",
      "530  Q 288+49  T 337  \u001b[91m\u001b[0m 327 \n",
      "532  Q 714+25  T 739  \u001b[91m\u001b[0m 748 \n",
      "533  Q 145+4   T 149  \u001b[91m\u001b[0m 159 \n",
      "534  Q 944+28  T 972  \u001b[91m\u001b[0m 962 \n",
      "535  Q 43+973  T 1016 \u001b[91m\u001b[0m 1006\n",
      "536  Q 183+27  T 210  \u001b[91m\u001b[0m 200 \n",
      "538  Q 5+157   T 162  \u001b[91m\u001b[0m 161 \n",
      "539  Q 161+39  T 200  \u001b[91m\u001b[0m 199 \n",
      "545  Q 27+762  T 789  \u001b[91m\u001b[0m 799 \n",
      "547  Q 107+387 T 494  \u001b[91m\u001b[0m 493 \n",
      "548  Q 55+509  T 564  \u001b[91m\u001b[0m 554 \n",
      "551  Q 261+477 T 738  \u001b[91m\u001b[0m 748 \n",
      "553  Q 342+415 T 757  \u001b[91m\u001b[0m 756 \n",
      "558  Q 107+9   T 116  \u001b[91m\u001b[0m 115 \n",
      "562  Q 859+42  T 901  \u001b[91m\u001b[0m 800 \n",
      "563  Q 6+576   T 582  \u001b[91m\u001b[0m 572 \n",
      "567  Q 82+2    T 84   \u001b[91m\u001b[0m 85  \n",
      "568  Q 837+531 T 1368 \u001b[91m\u001b[0m 1377\n",
      "569  Q 1+99    T 100  \u001b[91m\u001b[0m 109 \n",
      "571  Q 660+582 T 1242 \u001b[91m\u001b[0m 1152\n",
      "572  Q 904+527 T 1431 \u001b[91m\u001b[0m 1322\n",
      "574  Q 85+71   T 156  \u001b[91m\u001b[0m 155 \n",
      "575  Q 101+162 T 263  \u001b[91m\u001b[0m 273 \n",
      "577  Q 5+84    T 89   \u001b[91m\u001b[0m 81  \n",
      "578  Q 909+591 T 1500 \u001b[91m\u001b[0m 1400\n",
      "579  Q 241+40  T 281  \u001b[91m\u001b[0m 271 \n",
      "580  Q 95+80   T 175  \u001b[91m\u001b[0m 176 \n",
      "581  Q 431+229 T 660  \u001b[91m\u001b[0m 661 \n",
      "582  Q 752+111 T 863  \u001b[91m\u001b[0m 883 \n",
      "588  Q 83+245  T 328  \u001b[91m\u001b[0m 338 \n",
      "590  Q 259+92  T 351  \u001b[91m\u001b[0m 331 \n",
      "591  Q 200+28  T 228  \u001b[91m\u001b[0m 238 \n",
      "594  Q 51+5    T 56   \u001b[91m\u001b[0m 55  \n",
      "595  Q 81+336  T 417  \u001b[91m\u001b[0m 407 \n",
      "597  Q 5+567   T 572  \u001b[91m\u001b[0m 562 \n",
      "599  Q 688+82  T 770  \u001b[91m\u001b[0m 769 \n",
      "600  Q 64+468  T 532  \u001b[91m\u001b[0m 531 \n",
      "604  Q 788+757 T 1545 \u001b[91m\u001b[0m 1554\n",
      "605  Q 37+493  T 530  \u001b[91m\u001b[0m 520 \n",
      "607  Q 660+195 T 855  \u001b[91m\u001b[0m 856 \n",
      "608  Q 266+229 T 495  \u001b[91m\u001b[0m 584 \n",
      "609  Q 747+344 T 1091 \u001b[91m\u001b[0m 1080\n",
      "611  Q 750+72  T 822  \u001b[91m\u001b[0m 823 \n",
      "615  Q 95+256  T 351  \u001b[91m\u001b[0m 331 \n",
      "616  Q 694+148 T 842  \u001b[91m\u001b[0m 841 \n",
      "617  Q 697+21  T 718  \u001b[91m\u001b[0m 708 \n",
      "618  Q 77+295  T 372  \u001b[91m\u001b[0m 362 \n",
      "621  Q 11+692  T 703  \u001b[91m\u001b[0m 702 \n",
      "624  Q 737+556 T 1293 \u001b[91m\u001b[0m 1273\n",
      "625  Q 774+1   T 775  \u001b[91m\u001b[0m 774 \n",
      "627  Q 127+144 T 271  \u001b[91m\u001b[0m 161 \n",
      "628  Q 6+142   T 148  \u001b[91m\u001b[0m 159 \n",
      "629  Q 478+927 T 1405 \u001b[91m\u001b[0m 1375\n",
      "635  Q 836+448 T 1284 \u001b[91m\u001b[0m 1274\n",
      "636  Q 86+20   T 106  \u001b[91m\u001b[0m 166 \n",
      "637  Q 583+420 T 1003 \u001b[91m\u001b[0m 9902\n",
      "638  Q 667+57  T 724  \u001b[91m\u001b[0m 734 \n",
      "640  Q 61+10   T 71   \u001b[91m\u001b[0m 61  \n",
      "641  Q 739+96  T 835  \u001b[91m\u001b[0m 824 \n",
      "643  Q 16+401  T 417  \u001b[91m\u001b[0m 416 \n",
      "644  Q 921+28  T 949  \u001b[91m\u001b[0m 958 \n",
      "648  Q 353+294 T 647  \u001b[91m\u001b[0m 637 \n",
      "649  Q 59+713  T 772  \u001b[91m\u001b[0m 773 \n",
      "654  Q 977+553 T 1530 \u001b[91m\u001b[0m 1421\n",
      "655  Q 534+207 T 741  \u001b[91m\u001b[0m 751 \n",
      "657  Q 205+97  T 302  \u001b[91m\u001b[0m 311 \n",
      "658  Q 5+839   T 844  \u001b[91m\u001b[0m 843 \n",
      "660  Q 97+968  T 1065 \u001b[91m\u001b[0m 1075\n",
      "664  Q 601+746 T 1347 \u001b[91m\u001b[0m 1357\n",
      "667  Q 48+33   T 81   \u001b[91m\u001b[0m 80  \n",
      "668  Q 672+800 T 1472 \u001b[91m\u001b[0m 1482\n",
      "669  Q 31+89   T 120  \u001b[91m\u001b[0m 110 \n",
      "671  Q 160+470 T 630  \u001b[91m\u001b[0m 737 \n",
      "672  Q 53+51   T 104  \u001b[91m\u001b[0m 125 \n",
      "674  Q 33+960  T 993  \u001b[91m\u001b[0m 992 \n",
      "677  Q 865+85  T 950  \u001b[91m\u001b[0m 940 \n",
      "678  Q 961+323 T 1284 \u001b[91m\u001b[0m 1274\n",
      "681  Q 68+592  T 660  \u001b[91m\u001b[0m 670 \n",
      "684  Q 229+6   T 235  \u001b[91m\u001b[0m 245 \n",
      "685  Q 610+310 T 920  \u001b[91m\u001b[0m 951 \n",
      "686  Q 901+584 T 1485 \u001b[91m\u001b[0m 1405\n",
      "688  Q 594+99  T 693  \u001b[91m\u001b[0m 673 \n",
      "695  Q 78+681  T 759  \u001b[91m\u001b[0m 659 \n",
      "696  Q 402+33  T 435  \u001b[91m\u001b[0m 446 \n",
      "698  Q 52+567  T 619  \u001b[91m\u001b[0m 629 \n",
      "700  Q 444+504 T 948  \u001b[91m\u001b[0m 959 \n",
      "705  Q 512+432 T 944  \u001b[91m\u001b[0m 934 \n",
      "706  Q 910+981 T 1891 \u001b[91m\u001b[0m 1861\n",
      "710  Q 7+109   T 116  \u001b[91m\u001b[0m 115 \n",
      "711  Q 96+965  T 1061 \u001b[91m\u001b[0m 1071\n",
      "712  Q 95+879  T 974  \u001b[91m\u001b[0m 984 \n",
      "714  Q 242+60  T 302  \u001b[91m\u001b[0m 202 \n",
      "717  Q 61+70   T 131  \u001b[91m\u001b[0m 120 \n",
      "719  Q 75+764  T 839  \u001b[91m\u001b[0m 829 \n",
      "721  Q 683+52  T 735  \u001b[91m\u001b[0m 725 \n",
      "722  Q 23+37   T 60   \u001b[91m\u001b[0m 50  \n",
      "725  Q 201+604 T 805  \u001b[91m\u001b[0m 814 \n",
      "726  Q 252+266 T 518  \u001b[91m\u001b[0m 508 \n",
      "727  Q 143+298 T 441  \u001b[91m\u001b[0m 531 \n",
      "728  Q 261+454 T 715  \u001b[91m\u001b[0m 716 \n",
      "729  Q 397+568 T 965  \u001b[91m\u001b[0m 984 \n",
      "731  Q 78+51   T 129  \u001b[91m\u001b[0m 139 \n",
      "733  Q 87+266  T 353  \u001b[91m\u001b[0m 343 \n",
      "734  Q 50+24   T 74   \u001b[91m\u001b[0m 75  \n",
      "737  Q 49+22   T 71   \u001b[91m\u001b[0m 70  \n",
      "743  Q 28+230  T 258  \u001b[91m\u001b[0m 268 \n",
      "745  Q 82+795  T 877  \u001b[91m\u001b[0m 878 \n",
      "748  Q 496+962 T 1458 \u001b[91m\u001b[0m 1468\n",
      "752  Q 212+574 T 786  \u001b[91m\u001b[0m 776 \n",
      "754  Q 69+180  T 249  \u001b[91m\u001b[0m 299 \n",
      "756  Q 157+58  T 215  \u001b[91m\u001b[0m 225 \n",
      "757  Q 60+808  T 868  \u001b[91m\u001b[0m 768 \n",
      "758  Q 292+29  T 321  \u001b[91m\u001b[0m 311 \n",
      "762  Q 79+90   T 169  \u001b[91m\u001b[0m 179 \n",
      "768  Q 60+15   T 75   \u001b[91m\u001b[0m 76  \n",
      "772  Q 605+99  T 704  \u001b[91m\u001b[0m 794 \n",
      "773  Q 772+52  T 824  \u001b[91m\u001b[0m 825 \n",
      "774  Q 735+56  T 791  \u001b[91m\u001b[0m 781 \n",
      "777  Q 93+675  T 768  \u001b[91m\u001b[0m 769 \n",
      "779  Q 339+36  T 375  \u001b[91m\u001b[0m 364 \n",
      "780  Q 262+954 T 1216 \u001b[91m\u001b[0m 1227\n",
      "781  Q 734+264 T 998  \u001b[91m\u001b[0m 988 \n",
      "782  Q 834+844 T 1678 \u001b[91m\u001b[0m 1787\n",
      "783  Q 618+9   T 627  \u001b[91m\u001b[0m 626 \n",
      "788  Q 137+67  T 204  \u001b[91m\u001b[0m 284 \n",
      "789  Q 845+17  T 862  \u001b[91m\u001b[0m 872 \n",
      "790  Q 61+923  T 984  \u001b[91m\u001b[0m 974 \n",
      "791  Q 2+172   T 174  \u001b[91m\u001b[0m 173 \n",
      "792  Q 990+8   T 998  \u001b[91m\u001b[0m 999 \n",
      "794  Q 328+236 T 564  \u001b[91m\u001b[0m 554 \n",
      "797  Q 167+83  T 250  \u001b[91m\u001b[0m 241 \n",
      "803  Q 13+359  T 372  \u001b[91m\u001b[0m 371 \n",
      "804  Q 879+7   T 886  \u001b[91m\u001b[0m 875 \n",
      "805  Q 535+69  T 604  \u001b[91m\u001b[0m 614 \n",
      "809  Q 1+487   T 488  \u001b[91m\u001b[0m 489 \n",
      "813  Q 7+854   T 861  \u001b[91m\u001b[0m 851 \n",
      "814  Q 6+681   T 687  \u001b[91m\u001b[0m 688 \n",
      "818  Q 606+260 T 866  \u001b[91m\u001b[0m 876 \n",
      "820  Q 84+160  T 244  \u001b[91m\u001b[0m 243 \n",
      "821  Q 386+85  T 471  \u001b[91m\u001b[0m 472 \n",
      "822  Q 352+28  T 380  \u001b[91m\u001b[0m 370 \n",
      "823  Q 54+906  T 960  \u001b[91m\u001b[0m 950 \n",
      "824  Q 95+778  T 873  \u001b[91m\u001b[0m 872 \n",
      "826  Q 37+992  T 1029 \u001b[91m\u001b[0m 1028\n",
      "829  Q 889+631 T 1520 \u001b[91m\u001b[0m 1530\n",
      "830  Q 902+696 T 1598 \u001b[91m\u001b[0m 1688\n",
      "831  Q 50+852  T 902  \u001b[91m\u001b[0m 913 \n",
      "833  Q 935+385 T 1320 \u001b[91m\u001b[0m 1300\n",
      "834  Q 276+20  T 296  \u001b[91m\u001b[0m 286 \n",
      "835  Q 629+11  T 640  \u001b[91m\u001b[0m 630 \n",
      "836  Q 551+63  T 614  \u001b[91m\u001b[0m 624 \n",
      "837  Q 991+624 T 1615 \u001b[91m\u001b[0m 1747\n",
      "838  Q 448+77  T 525  \u001b[91m\u001b[0m 535 \n",
      "839  Q 190+448 T 638  \u001b[91m\u001b[0m 629 \n",
      "840  Q 933+912 T 1845 \u001b[91m\u001b[0m 1855\n",
      "842  Q 367+174 T 541  \u001b[91m\u001b[0m 542 \n",
      "843  Q 513+5   T 518  \u001b[91m\u001b[0m 517 \n",
      "844  Q 446+26  T 472  \u001b[91m\u001b[0m 471 \n",
      "845  Q 755+102 T 857  \u001b[91m\u001b[0m 866 \n",
      "849  Q 634+98  T 732  \u001b[91m\u001b[0m 741 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852  Q 938+15  T 953  \u001b[91m\u001b[0m 952 \n",
      "853  Q 215+450 T 665  \u001b[91m\u001b[0m 776 \n",
      "855  Q 3+997   T 1000 \u001b[91m\u001b[0m 990 \n",
      "856  Q 98+537  T 635  \u001b[91m\u001b[0m 625 \n",
      "857  Q 389+40  T 429  \u001b[91m\u001b[0m 439 \n",
      "858  Q 511+281 T 792  \u001b[91m\u001b[0m 692 \n",
      "860  Q 302+552 T 854  \u001b[91m\u001b[0m 874 \n",
      "862  Q 281+26  T 307  \u001b[91m\u001b[0m 308 \n",
      "863  Q 731+60  T 791  \u001b[91m\u001b[0m 781 \n",
      "865  Q 483+138 T 621  \u001b[91m\u001b[0m 622 \n",
      "866  Q 502+47  T 549  \u001b[91m\u001b[0m 559 \n",
      "867  Q 239+43  T 282  \u001b[91m\u001b[0m 283 \n",
      "870  Q 764+73  T 837  \u001b[91m\u001b[0m 847 \n",
      "871  Q 201+17  T 218  \u001b[91m\u001b[0m 227 \n",
      "872  Q 402+376 T 778  \u001b[91m\u001b[0m 799 \n",
      "876  Q 8+626   T 634  \u001b[91m\u001b[0m 644 \n",
      "880  Q 903+592 T 1495 \u001b[91m\u001b[0m 1484\n",
      "881  Q 598+53  T 651  \u001b[91m\u001b[0m 642 \n",
      "882  Q 480+18  T 498  \u001b[91m\u001b[0m 499 \n",
      "886  Q 398+305 T 703  \u001b[91m\u001b[0m 743 \n",
      "887  Q 47+214  T 261  \u001b[91m\u001b[0m 251 \n",
      "888  Q 606+435 T 1041 \u001b[91m\u001b[0m 1151\n",
      "889  Q 467+2   T 469  \u001b[91m\u001b[0m 479 \n",
      "890  Q 261+625 T 886  \u001b[91m\u001b[0m 987 \n",
      "891  Q 925+16  T 941  \u001b[91m\u001b[0m 931 \n",
      "892  Q 322+8   T 330  \u001b[91m\u001b[0m 329 \n",
      "893  Q 72+920  T 992  \u001b[91m\u001b[0m 993 \n",
      "894  Q 68+580  T 648  \u001b[91m\u001b[0m 638 \n",
      "896  Q 650+632 T 1282 \u001b[91m\u001b[0m 1292\n",
      "897  Q 15+456  T 471  \u001b[91m\u001b[0m 481 \n",
      "898  Q 29+562  T 591  \u001b[91m\u001b[0m 581 \n",
      "902  Q 371+74  T 445  \u001b[91m\u001b[0m 444 \n",
      "903  Q 846+69  T 915  \u001b[91m\u001b[0m 934 \n",
      "904  Q 941+85  T 1026 \u001b[91m\u001b[0m 1037\n",
      "906  Q 436+938 T 1374 \u001b[91m\u001b[0m 1385\n",
      "908  Q 436+797 T 1233 \u001b[91m\u001b[0m 1223\n",
      "911  Q 79+201  T 280  \u001b[91m\u001b[0m 289 \n",
      "914  Q 973+949 T 1922 \u001b[91m\u001b[0m 1809\n",
      "916  Q 33+7    T 40   \u001b[91m\u001b[0m 30  \n",
      "921  Q 855+220 T 1075 \u001b[91m\u001b[0m 1066\n",
      "924  Q 460+55  T 515  \u001b[91m\u001b[0m 516 \n",
      "927  Q 201+607 T 808  \u001b[91m\u001b[0m 818 \n",
      "931  Q 20+415  T 435  \u001b[91m\u001b[0m 445 \n",
      "932  Q 1+892   T 893  \u001b[91m\u001b[0m 803 \n",
      "933  Q 607+381 T 988  \u001b[91m\u001b[0m 987 \n",
      "940  Q 560+793 T 1353 \u001b[91m\u001b[0m 1354\n",
      "943  Q 296+92  T 388  \u001b[91m\u001b[0m 389 \n",
      "949  Q 43+159  T 202  \u001b[91m\u001b[0m 212 \n",
      "950  Q 86+91   T 177  \u001b[91m\u001b[0m 186 \n",
      "951  Q 290+149 T 439  \u001b[91m\u001b[0m 429 \n",
      "953  Q 916+14  T 930  \u001b[91m\u001b[0m 920 \n",
      "955  Q 23+974  T 997  \u001b[91m\u001b[0m 907 \n",
      "958  Q 979+34  T 1013 \u001b[91m\u001b[0m 1024\n",
      "959  Q 73+298  T 371  \u001b[91m\u001b[0m 372 \n",
      "960  Q 39+117  T 156  \u001b[91m\u001b[0m 166 \n",
      "962  Q 977+959 T 1936 \u001b[91m\u001b[0m 1934\n",
      "963  Q 307+928 T 1235 \u001b[91m\u001b[0m 1205\n",
      "964  Q 118+906 T 1024 \u001b[91m\u001b[0m 1034\n",
      "966  Q 9+957   T 966  \u001b[91m\u001b[0m 967 \n",
      "969  Q 5+567   T 572  \u001b[91m\u001b[0m 562 \n",
      "973  Q 602+129 T 731  \u001b[91m\u001b[0m 892 \n",
      "974  Q 52+79   T 131  \u001b[91m\u001b[0m 132 \n",
      "977  Q 740+23  T 763  \u001b[91m\u001b[0m 762 \n",
      "980  Q 992+4   T 996  \u001b[91m\u001b[0m 997 \n",
      "981  Q 19+879  T 898  \u001b[91m\u001b[0m 897 \n",
      "982  Q 868+83  T 951  \u001b[91m\u001b[0m 961 \n",
      "985  Q 603+168 T 771  \u001b[91m\u001b[0m 772 \n",
      "989  Q 644+16  T 660  \u001b[91m\u001b[0m 650 \n",
      "990  Q 453+96  T 549  \u001b[91m\u001b[0m 540 \n",
      "996  Q 515+20  T 535  \u001b[91m\u001b[0m 525 \n",
      "997  Q 68+486  T 554  \u001b[91m\u001b[0m 544 \n",
      "999  Q 51+616  T 667  \u001b[91m\u001b[0m 668 \n",
      "accu: 0.47\n"
     ]
    }
   ],
   "source": [
    "print(\"MSG : Prediction\")\n",
    "#####################################################\n",
    "## Try to test and evaluate your model ##############\n",
    "## ex. test_x = [\"555+175\", \"860+7  \", \"340+29 \"]\n",
    "## ex. test_y = [\"730 \", \"867 \", \"369 \"] \n",
    "#####################################################\n",
    "#####################################################\n",
    "correct_ct = 0\n",
    "accuracy = 0\n",
    "for i in range(len(test_x)):\n",
    "    ind = np.random.randint(0, len(test_x))\n",
    "    rowx, rowy = test_x[np.array([ind])], test_y[np.array([ind])]\n",
    "    preds = model.predict_classes(rowx, verbose=0)\n",
    "    q = ctable.decode(rowx[0])\n",
    "    correct = ctable.decode(rowy[0])\n",
    "    guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        correct_ct = correct_ct + 1\n",
    "    else: \n",
    "        if i < 1000:\n",
    "            print(i, ' Q', q[::-1] if REVERSE else q, end=' ')\n",
    "            print('T', correct, end=' ')\n",
    "            print(colors.fail + '' + colors.close, end=' ')\n",
    "            print(guess)\n",
    "accuracy = correct_ct/len(test_x)\n",
    "print('accu:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accu: 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
