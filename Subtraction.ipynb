{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 80000\n",
    "DIGITS = 3\n",
    "REVERSE = False\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = '0123456789- '\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '-',\n",
       " 2: '0',\n",
       " 3: '1',\n",
       " 4: '2',\n",
       " 5: '3',\n",
       " 6: '4',\n",
       " 7: '5',\n",
       " 8: '6',\n",
       " 9: '7',\n",
       " 10: '8',\n",
       " 11: '9'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctable.indices_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 80000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "num = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789')) for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    num = [f(),f()]\n",
    "    num.sort()\n",
    "    a = num[1]\n",
    "    b = num[0]\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    q = '{}-{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a - b)\n",
    "    ans += ' ' * (DIGITS - len(ans))\n",
    "    if REVERSE:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['76-7   ', '79-60  ', '88-9   ', '290-43 ', '63-29  '] ['69 ', '19 ', '79 ', '247', '34 ']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5], expected[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(expected), DIGITS, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(18000, 7, 12)\n",
      "(18000, 3, 12)\n",
      "Validation Data:\n",
      "(2000, 7, 12)\n",
      "(2000, 3, 12)\n",
      "Testing Data:\n",
      "(60000, 7, 12)\n",
      "(60000, 3, 12)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# train_test_split\n",
    "train_x = x[:20000]\n",
    "train_y = y[:20000]\n",
    "test_x = x[20000:]\n",
    "test_y = y[20000:]\n",
    "\n",
    "split_at = len(train_x) - len(train_x) // 10\n",
    "(x_train, x_val) = train_x[:split_at], train_x[split_at:]\n",
    "(y_train, y_val) = train_y[:split_at], train_y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  [[[False False False False False False False False False False False\n",
      "    True]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False  True False False False False False False False\n",
      "   False]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False False False False False False  True False\n",
      "   False]\n",
      "  [False False False False False False False False False False False\n",
      "    True]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False  True False False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False False\n",
      "    True]\n",
      "  [False False False False False False False False False False False\n",
      "    True]]\n",
      "\n",
      " [[False False False False False False False False  True False False\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]\n",
      "  [False  True False False False False False False False False False\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False  True False False False False False False False False\n",
      "   False]]] \n",
      "\n",
      " label:  [[[False False False False False False False False False False  True\n",
      "   False]\n",
      "  [False False False False  True False False False False False False\n",
      "   False]\n",
      "  [ True False False False False False False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False False False False  True False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False False\n",
      "    True]\n",
      "  [False False False False False  True False False False False False\n",
      "   False]]\n",
      "\n",
      " [[False False False False False  True False False False False False\n",
      "   False]\n",
      "  [False False False False False False False False False False False\n",
      "    True]\n",
      "  [False False False False False False False False  True False False\n",
      "   False]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"input: \", x_train[:3], '\\n\\n', \"label: \", y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\SCREAM\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 3, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 3, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "############################################\n",
    "##### Build your own model here ############\n",
    "############################################\n",
    "n_chars = len(chars)\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(layers.RepeatVector(DIGITS))\n",
    "for _ in range(LAYERS):\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SCREAM\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "18000/18000 [==============================] - 11s 588us/step - loss: 2.3341 - acc: 0.1296 - val_loss: 2.2826 - val_acc: 0.1378\n",
      "Epoch 2/200\n",
      "18000/18000 [==============================] - 5s 255us/step - loss: 2.2192 - acc: 0.1739 - val_loss: 2.1402 - val_acc: 0.1990\n",
      "Epoch 3/200\n",
      "18000/18000 [==============================] - 4s 248us/step - loss: 2.0604 - acc: 0.2360 - val_loss: 2.0188 - val_acc: 0.2480\n",
      "Epoch 4/200\n",
      "18000/18000 [==============================] - 5s 259us/step - loss: 1.9611 - acc: 0.2742 - val_loss: 1.9240 - val_acc: 0.2862\n",
      "Epoch 5/200\n",
      "18000/18000 [==============================] - 4s 248us/step - loss: 1.8972 - acc: 0.2973 - val_loss: 1.8610 - val_acc: 0.3023\n",
      "Epoch 6/200\n",
      "18000/18000 [==============================] - 5s 253us/step - loss: 1.8470 - acc: 0.3164 - val_loss: 1.8404 - val_acc: 0.3123\n",
      "Epoch 7/200\n",
      "18000/18000 [==============================] - 5s 260us/step - loss: 1.7962 - acc: 0.3367 - val_loss: 1.7631 - val_acc: 0.3470\n",
      "Epoch 8/200\n",
      "18000/18000 [==============================] - 5s 252us/step - loss: 1.7524 - acc: 0.3522 - val_loss: 1.7156 - val_acc: 0.3692\n",
      "Epoch 9/200\n",
      "18000/18000 [==============================] - 5s 251us/step - loss: 1.7034 - acc: 0.3722 - val_loss: 1.6776 - val_acc: 0.3740\n",
      "Epoch 10/200\n",
      "18000/18000 [==============================] - 4s 249us/step - loss: 1.6523 - acc: 0.3939 - val_loss: 1.6343 - val_acc: 0.3920\n",
      "Epoch 11/200\n",
      "18000/18000 [==============================] - 5s 264us/step - loss: 1.6178 - acc: 0.4050 - val_loss: 1.6344 - val_acc: 0.3872\n",
      "Epoch 12/200\n",
      "18000/18000 [==============================] - 5s 259us/step - loss: 1.5801 - acc: 0.4224 - val_loss: 1.5563 - val_acc: 0.4243A: 1s - loss\n",
      "Epoch 13/200\n",
      "18000/18000 [==============================] - 5s 265us/step - loss: 1.5521 - acc: 0.4285 - val_loss: 1.5633 - val_acc: 0.4090\n",
      "Epoch 14/200\n",
      "18000/18000 [==============================] - 4s 236us/step - loss: 1.5226 - acc: 0.4420 - val_loss: 1.5509 - val_acc: 0.4040\n",
      "Epoch 15/200\n",
      "18000/18000 [==============================] - 4s 225us/step - loss: 1.5034 - acc: 0.4454 - val_loss: 1.4939 - val_acc: 0.4398\n",
      "Epoch 16/200\n",
      "18000/18000 [==============================] - 4s 226us/step - loss: 1.4810 - acc: 0.4515 - val_loss: 1.4615 - val_acc: 0.4507\n",
      "Epoch 17/200\n",
      "18000/18000 [==============================] - 4s 225us/step - loss: 1.4482 - acc: 0.4694 - val_loss: 1.4873 - val_acc: 0.4388\n",
      "Epoch 18/200\n",
      "18000/18000 [==============================] - 4s 235us/step - loss: 1.4353 - acc: 0.4716 - val_loss: 1.4333 - val_acc: 0.4713\n",
      "Epoch 19/200\n",
      "18000/18000 [==============================] - 4s 228us/step - loss: 1.4183 - acc: 0.4791 - val_loss: 1.4107 - val_acc: 0.4697\n",
      "Epoch 20/200\n",
      "18000/18000 [==============================] - 4s 226us/step - loss: 1.3930 - acc: 0.4892 - val_loss: 1.3918 - val_acc: 0.4818\n",
      "Epoch 21/200\n",
      "18000/18000 [==============================] - 4s 225us/step - loss: 1.3691 - acc: 0.4979 - val_loss: 1.3715 - val_acc: 0.4955\n",
      "Epoch 22/200\n",
      "18000/18000 [==============================] - 4s 234us/step - loss: 1.3631 - acc: 0.4970 - val_loss: 1.3766 - val_acc: 0.4800\n",
      "Epoch 23/200\n",
      "18000/18000 [==============================] - 4s 225us/step - loss: 1.3328 - acc: 0.5134 - val_loss: 1.3604 - val_acc: 0.4818\n",
      "Epoch 24/200\n",
      "18000/18000 [==============================] - 4s 226us/step - loss: 1.3199 - acc: 0.5175 - val_loss: 1.3456 - val_acc: 0.5010\n",
      "Epoch 25/200\n",
      "18000/18000 [==============================] - 4s 226us/step - loss: 1.3089 - acc: 0.5176 - val_loss: 1.3041 - val_acc: 0.5165\n",
      "Epoch 26/200\n",
      "18000/18000 [==============================] - 4s 235us/step - loss: 1.2898 - acc: 0.5266 - val_loss: 1.3115 - val_acc: 0.5068\n",
      "Epoch 27/200\n",
      "18000/18000 [==============================] - 4s 228us/step - loss: 1.2742 - acc: 0.5331 - val_loss: 1.2889 - val_acc: 0.5173\n",
      "Epoch 28/200\n",
      "18000/18000 [==============================] - 4s 228us/step - loss: 1.2569 - acc: 0.5382 - val_loss: 1.2703 - val_acc: 0.5323\n",
      "Epoch 29/200\n",
      "18000/18000 [==============================] - 4s 235us/step - loss: 1.2349 - acc: 0.5499 - val_loss: 1.2468 - val_acc: 0.5450\n",
      "Epoch 30/200\n",
      "18000/18000 [==============================] - 5s 265us/step - loss: 1.2197 - acc: 0.5552 - val_loss: 1.2466 - val_acc: 0.5363\n",
      "Epoch 31/200\n",
      "18000/18000 [==============================] - 4s 236us/step - loss: 1.2050 - acc: 0.5598 - val_loss: 1.2567 - val_acc: 0.5282\n",
      "Epoch 32/200\n",
      "18000/18000 [==============================] - 4s 230us/step - loss: 1.1887 - acc: 0.5647 - val_loss: 1.2127 - val_acc: 0.5513\n",
      "Epoch 33/200\n",
      "18000/18000 [==============================] - 4s 235us/step - loss: 1.1761 - acc: 0.5712 - val_loss: 1.2132 - val_acc: 0.5455\n",
      "Epoch 34/200\n",
      "18000/18000 [==============================] - 4s 225us/step - loss: 1.1595 - acc: 0.5787 - val_loss: 1.1889 - val_acc: 0.5642\n",
      "Epoch 35/200\n",
      "18000/18000 [==============================] - 4s 228us/step - loss: 1.1421 - acc: 0.5843 - val_loss: 1.1688 - val_acc: 0.5697\n",
      "Epoch 36/200\n",
      "18000/18000 [==============================] - 4s 229us/step - loss: 1.1253 - acc: 0.5904 - val_loss: 1.1639 - val_acc: 0.5618\n",
      "Epoch 37/200\n",
      "18000/18000 [==============================] - 4s 236us/step - loss: 1.1124 - acc: 0.5928 - val_loss: 1.1461 - val_acc: 0.5695\n",
      "Epoch 38/200\n",
      "18000/18000 [==============================] - 4s 227us/step - loss: 1.0931 - acc: 0.6039 - val_loss: 1.1446 - val_acc: 0.5735\n",
      "Epoch 39/200\n",
      "18000/18000 [==============================] - 4s 225us/step - loss: 1.0878 - acc: 0.5998 - val_loss: 1.1165 - val_acc: 0.5778\n",
      "Epoch 40/200\n",
      "18000/18000 [==============================] - 4s 227us/step - loss: 1.0687 - acc: 0.6096 - val_loss: 1.1518 - val_acc: 0.5600\n",
      "Epoch 41/200\n",
      "18000/18000 [==============================] - 4s 234us/step - loss: 1.0470 - acc: 0.6174 - val_loss: 1.0901 - val_acc: 0.5990\n",
      "Epoch 42/200\n",
      "18000/18000 [==============================] - 5s 256us/step - loss: 1.0410 - acc: 0.6160 - val_loss: 1.1161 - val_acc: 0.5697\n",
      "Epoch 43/200\n",
      "18000/18000 [==============================] - 5s 265us/step - loss: 1.0131 - acc: 0.6314 - val_loss: 1.0641 - val_acc: 0.6065\n",
      "Epoch 44/200\n",
      "18000/18000 [==============================] - 5s 269us/step - loss: 0.9942 - acc: 0.6372 - val_loss: 1.0265 - val_acc: 0.6193\n",
      "Epoch 45/200\n",
      "18000/18000 [==============================] - 5s 253us/step - loss: 0.9777 - acc: 0.6428 - val_loss: 1.0320 - val_acc: 0.6157\n",
      "Epoch 46/200\n",
      "18000/18000 [==============================] - 4s 227us/step - loss: 0.9495 - acc: 0.6558 - val_loss: 0.9987 - val_acc: 0.6338\n",
      "Epoch 47/200\n",
      "18000/18000 [==============================] - 4s 226us/step - loss: 0.9285 - acc: 0.6605 - val_loss: 0.9855 - val_acc: 0.6257\n",
      "Epoch 48/200\n",
      "18000/18000 [==============================] - 4s 236us/step - loss: 0.9138 - acc: 0.6640 - val_loss: 0.9651 - val_acc: 0.6285\n",
      "Epoch 49/200\n",
      "18000/18000 [==============================] - 4s 231us/step - loss: 0.8837 - acc: 0.6764 - val_loss: 0.9554 - val_acc: 0.6350\n",
      "Epoch 50/200\n",
      "18000/18000 [==============================] - 5s 274us/step - loss: 0.8600 - acc: 0.6861 - val_loss: 0.8875 - val_acc: 0.6700\n",
      "Epoch 51/200\n",
      "18000/18000 [==============================] - 5s 252us/step - loss: 0.8255 - acc: 0.6997 - val_loss: 0.8670 - val_acc: 0.6653\n",
      "Epoch 52/200\n",
      "18000/18000 [==============================] - 5s 261us/step - loss: 0.8022 - acc: 0.7078 - val_loss: 0.8610 - val_acc: 0.6667\n",
      "Epoch 53/200\n",
      "18000/18000 [==============================] - 4s 244us/step - loss: 0.7748 - acc: 0.7202 - val_loss: 0.8300 - val_acc: 0.6808\n",
      "Epoch 54/200\n",
      "18000/18000 [==============================] - 4s 247us/step - loss: 0.7509 - acc: 0.7266 - val_loss: 0.8375 - val_acc: 0.6673\n",
      "Epoch 55/200\n",
      "18000/18000 [==============================] - 5s 251us/step - loss: 0.7150 - acc: 0.7389 - val_loss: 0.7960 - val_acc: 0.6907\n",
      "Epoch 56/200\n",
      "18000/18000 [==============================] - 5s 261us/step - loss: 0.6887 - acc: 0.7505 - val_loss: 0.7311 - val_acc: 0.7208\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 4s 227us/step - loss: 0.6530 - acc: 0.7667 - val_loss: 0.7062 - val_acc: 0.7222\n",
      "Epoch 58/200\n",
      "18000/18000 [==============================] - 4s 235us/step - loss: 0.6272 - acc: 0.7784 - val_loss: 0.6792 - val_acc: 0.7375\n",
      "Epoch 59/200\n",
      "18000/18000 [==============================] - 4s 245us/step - loss: 0.5967 - acc: 0.7896 - val_loss: 0.6617 - val_acc: 0.7448\n",
      "Epoch 60/200\n",
      "18000/18000 [==============================] - 4s 236us/step - loss: 0.5769 - acc: 0.7982 - val_loss: 0.6324 - val_acc: 0.7540\n",
      "Epoch 61/200\n",
      "18000/18000 [==============================] - 4s 232us/step - loss: 0.5459 - acc: 0.8118 - val_loss: 0.6065 - val_acc: 0.7688\n",
      "Epoch 62/200\n",
      "18000/18000 [==============================] - 4s 229us/step - loss: 0.5180 - acc: 0.8259 - val_loss: 0.5853 - val_acc: 0.7823\n",
      "Epoch 63/200\n",
      "18000/18000 [==============================] - 4s 237us/step - loss: 0.4947 - acc: 0.8357 - val_loss: 0.6077 - val_acc: 0.7617\n",
      "Epoch 64/200\n",
      "18000/18000 [==============================] - 4s 229us/step - loss: 0.4811 - acc: 0.8391 - val_loss: 0.5482 - val_acc: 0.7853\n",
      "Epoch 65/200\n",
      "18000/18000 [==============================] - 4s 234us/step - loss: 0.4510 - acc: 0.8532 - val_loss: 0.5092 - val_acc: 0.8185\n",
      "Epoch 66/200\n",
      "18000/18000 [==============================] - 4s 245us/step - loss: 0.4316 - acc: 0.8631 - val_loss: 0.5139 - val_acc: 0.8032\n",
      "Epoch 67/200\n",
      "18000/18000 [==============================] - 5s 255us/step - loss: 0.4113 - acc: 0.8699 - val_loss: 0.4796 - val_acc: 0.8278\n",
      "Epoch 68/200\n",
      "18000/18000 [==============================] - 5s 257us/step - loss: 0.3896 - acc: 0.8817 - val_loss: 0.4493 - val_acc: 0.8357\n",
      "Epoch 69/200\n",
      "18000/18000 [==============================] - 4s 249us/step - loss: 0.3711 - acc: 0.8891 - val_loss: 0.4290 - val_acc: 0.8492\n",
      "Epoch 70/200\n",
      "18000/18000 [==============================] - 4s 248us/step - loss: 0.3615 - acc: 0.8906 - val_loss: 0.4405 - val_acc: 0.8345\n",
      "Epoch 71/200\n",
      "18000/18000 [==============================] - 4s 240us/step - loss: 0.3429 - acc: 0.8988 - val_loss: 0.4090 - val_acc: 0.8528\n",
      "Epoch 72/200\n",
      "18000/18000 [==============================] - 4s 233us/step - loss: 0.3250 - acc: 0.9057 - val_loss: 0.4041 - val_acc: 0.8577\n",
      "Epoch 73/200\n",
      "18000/18000 [==============================] - 4s 232us/step - loss: 0.3130 - acc: 0.9092 - val_loss: 0.3677 - val_acc: 0.8737\n",
      "Epoch 74/200\n",
      "18000/18000 [==============================] - 4s 249us/step - loss: 0.2974 - acc: 0.9167 - val_loss: 0.3735 - val_acc: 0.8688\n",
      "Epoch 75/200\n",
      "18000/18000 [==============================] - 4s 245us/step - loss: 0.2820 - acc: 0.9229 - val_loss: 0.3590 - val_acc: 0.8760\n",
      "Epoch 76/200\n",
      "18000/18000 [==============================] - 5s 269us/step - loss: 0.2722 - acc: 0.9251 - val_loss: 0.3476 - val_acc: 0.8783\n",
      "Epoch 77/200\n",
      "18000/18000 [==============================] - 5s 289us/step - loss: 0.2613 - acc: 0.9293 - val_loss: 0.3306 - val_acc: 0.8853\n",
      "Epoch 78/200\n",
      "18000/18000 [==============================] - 5s 287us/step - loss: 0.2551 - acc: 0.9300 - val_loss: 0.3185 - val_acc: 0.8908\n",
      "Epoch 79/200\n",
      "18000/18000 [==============================] - 5s 286us/step - loss: 0.2380 - acc: 0.9371 - val_loss: 0.3223 - val_acc: 0.8872\n",
      "Epoch 80/200\n",
      "18000/18000 [==============================] - 4s 239us/step - loss: 0.2342 - acc: 0.9371 - val_loss: 0.3191 - val_acc: 0.8845\n",
      "Epoch 81/200\n",
      "18000/18000 [==============================] - 5s 266us/step - loss: 0.2214 - acc: 0.9425 - val_loss: 0.2995 - val_acc: 0.8943\n",
      "Epoch 82/200\n",
      "18000/18000 [==============================] - 5s 270us/step - loss: 0.2101 - acc: 0.9460 - val_loss: 0.2998 - val_acc: 0.8903\n",
      "Epoch 83/200\n",
      "18000/18000 [==============================] - 5s 250us/step - loss: 0.2066 - acc: 0.9464 - val_loss: 0.2878 - val_acc: 0.9012\n",
      "Epoch 84/200\n",
      "18000/18000 [==============================] - 5s 263us/step - loss: 0.1956 - acc: 0.9508 - val_loss: 0.2729 - val_acc: 0.9047\n",
      "Epoch 85/200\n",
      "18000/18000 [==============================] - 5s 252us/step - loss: 0.1904 - acc: 0.9504 - val_loss: 0.2826 - val_acc: 0.9000\n",
      "Epoch 86/200\n",
      "18000/18000 [==============================] - 4s 250us/step - loss: 0.1864 - acc: 0.9514 - val_loss: 0.2792 - val_acc: 0.8993\n",
      "Epoch 87/200\n",
      "18000/18000 [==============================] - 5s 260us/step - loss: 0.1765 - acc: 0.9551 - val_loss: 0.2640 - val_acc: 0.9050loss:\n",
      "Epoch 88/200\n",
      "18000/18000 [==============================] - 5s 257us/step - loss: 0.1815 - acc: 0.9501 - val_loss: 0.2575 - val_acc: 0.9093\n",
      "Epoch 89/200\n",
      "18000/18000 [==============================] - 4s 250us/step - loss: 0.1626 - acc: 0.9590 - val_loss: 0.2530 - val_acc: 0.9135\n",
      "Epoch 90/200\n",
      "18000/18000 [==============================] - 5s 265us/step - loss: 0.1538 - acc: 0.9635 - val_loss: 0.2271 - val_acc: 0.9230\n",
      "Epoch 91/200\n",
      "18000/18000 [==============================] - 5s 286us/step - loss: 0.1552 - acc: 0.9600 - val_loss: 0.2297 - val_acc: 0.9195\n",
      "Epoch 92/200\n",
      "18000/18000 [==============================] - 5s 276us/step - loss: 0.1570 - acc: 0.9583 - val_loss: 0.2426 - val_acc: 0.9117\n",
      "Epoch 93/200\n",
      "18000/18000 [==============================] - 5s 294us/step - loss: 0.1497 - acc: 0.9619 - val_loss: 0.2245 - val_acc: 0.9215\n",
      "Epoch 94/200\n",
      "18000/18000 [==============================] - 5s 293us/step - loss: 0.1401 - acc: 0.9658 - val_loss: 0.2429 - val_acc: 0.9147\n",
      "Epoch 95/200\n",
      "18000/18000 [==============================] - 5s 265us/step - loss: 0.1290 - acc: 0.9694 - val_loss: 0.2176 - val_acc: 0.9222\n",
      "Epoch 96/200\n",
      "18000/18000 [==============================] - 5s 258us/step - loss: 0.1287 - acc: 0.9691 - val_loss: 0.2214 - val_acc: 0.9217\n",
      "Epoch 97/200\n",
      "18000/18000 [==============================] - 5s 269us/step - loss: 0.1394 - acc: 0.9622 - val_loss: 0.2063 - val_acc: 0.9278\n",
      "Epoch 98/200\n",
      "18000/18000 [==============================] - 5s 258us/step - loss: 0.1136 - acc: 0.9755 - val_loss: 0.1956 - val_acc: 0.9318\n",
      "Epoch 99/200\n",
      "18000/18000 [==============================] - 5s 263us/step - loss: 0.1142 - acc: 0.9738 - val_loss: 0.2361 - val_acc: 0.9157\n",
      "Epoch 100/200\n",
      "18000/18000 [==============================] - 5s 271us/step - loss: 0.1132 - acc: 0.9745 - val_loss: 0.1911 - val_acc: 0.9335\n",
      "Epoch 101/200\n",
      "18000/18000 [==============================] - 5s 285us/step - loss: 0.1128 - acc: 0.9723 - val_loss: 0.1955 - val_acc: 0.9310\n",
      "Epoch 102/200\n",
      "18000/18000 [==============================] - 5s 265us/step - loss: 0.1624 - acc: 0.9499 - val_loss: 0.1989 - val_acc: 0.9282\n",
      "Epoch 103/200\n",
      "18000/18000 [==============================] - 5s 262us/step - loss: 0.0971 - acc: 0.9799 - val_loss: 0.1848 - val_acc: 0.9312\n",
      "Epoch 104/200\n",
      "18000/18000 [==============================] - 5s 261us/step - loss: 0.0931 - acc: 0.9809 - val_loss: 0.2035 - val_acc: 0.9302\n",
      "Epoch 105/200\n",
      "18000/18000 [==============================] - 5s 276us/step - loss: 0.0934 - acc: 0.9799 - val_loss: 0.1711 - val_acc: 0.9413\n",
      "Epoch 106/200\n",
      "18000/18000 [==============================] - 5s 261us/step - loss: 0.0900 - acc: 0.9808 - val_loss: 0.1760 - val_acc: 0.9378\n",
      "Epoch 107/200\n",
      "18000/18000 [==============================] - 5s 286us/step - loss: 0.0872 - acc: 0.9817 - val_loss: 0.1736 - val_acc: 0.9383\n",
      "Epoch 108/200\n",
      "18000/18000 [==============================] - 5s 275us/step - loss: 0.1071 - acc: 0.9719 - val_loss: 0.2158 - val_acc: 0.9263\n",
      "Epoch 109/200\n",
      "18000/18000 [==============================] - 5s 263us/step - loss: 0.0998 - acc: 0.9745 - val_loss: 0.1905 - val_acc: 0.9345\n",
      "Epoch 110/200\n",
      "18000/18000 [==============================] - 5s 264us/step - loss: 0.0808 - acc: 0.9836 - val_loss: 0.1678 - val_acc: 0.9410\n",
      "Epoch 111/200\n",
      "18000/18000 [==============================] - 5s 261us/step - loss: 0.0807 - acc: 0.9834 - val_loss: 0.1714 - val_acc: 0.9388\n",
      "Epoch 112/200\n",
      "18000/18000 [==============================] - 5s 272us/step - loss: 0.0821 - acc: 0.9822 - val_loss: 0.1721 - val_acc: 0.9363\n",
      "Epoch 113/200\n",
      "18000/18000 [==============================] - 5s 280us/step - loss: 0.0774 - acc: 0.9834 - val_loss: 0.1583 - val_acc: 0.9435\n",
      "Epoch 114/200\n",
      "18000/18000 [==============================] - 5s 274us/step - loss: 0.0756 - acc: 0.9844 - val_loss: 0.1622 - val_acc: 0.9423\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 5s 272us/step - loss: 0.0679 - acc: 0.9871 - val_loss: 0.1522 - val_acc: 0.9493\n",
      "Epoch 116/200\n",
      "18000/18000 [==============================] - 5s 274us/step - loss: 0.0689 - acc: 0.9853 - val_loss: 0.1819 - val_acc: 0.9342\n",
      "Epoch 117/200\n",
      "18000/18000 [==============================] - 5s 261us/step - loss: 0.0822 - acc: 0.9801 - val_loss: 0.1761 - val_acc: 0.9348\n",
      "Epoch 118/200\n",
      "18000/18000 [==============================] - 5s 252us/step - loss: 0.0926 - acc: 0.9751 - val_loss: 0.1958 - val_acc: 0.9308\n",
      "Epoch 119/200\n",
      "18000/18000 [==============================] - 5s 254us/step - loss: 0.0901 - acc: 0.9753 - val_loss: 0.1698 - val_acc: 0.9387\n",
      "Epoch 120/200\n",
      "18000/18000 [==============================] - 5s 255us/step - loss: 0.0701 - acc: 0.9839 - val_loss: 0.1619 - val_acc: 0.9443\n",
      "Epoch 121/200\n",
      "18000/18000 [==============================] - 5s 262us/step - loss: 0.0804 - acc: 0.9798 - val_loss: 0.1556 - val_acc: 0.9443\n",
      "Epoch 122/200\n",
      "18000/18000 [==============================] - 5s 254us/step - loss: 0.0657 - acc: 0.9860 - val_loss: 0.1406 - val_acc: 0.9512\n",
      "Epoch 123/200\n",
      "18000/18000 [==============================] - 5s 256us/step - loss: 0.0523 - acc: 0.9909 - val_loss: 0.1337 - val_acc: 0.9533\n",
      "Epoch 124/200\n",
      "18000/18000 [==============================] - 5s 278us/step - loss: 0.0505 - acc: 0.9912 - val_loss: 0.1335 - val_acc: 0.9518\n",
      "Epoch 125/200\n",
      "18000/18000 [==============================] - 4s 249us/step - loss: 0.0500 - acc: 0.9916 - val_loss: 0.1322 - val_acc: 0.9538\n",
      "Epoch 126/200\n",
      "18000/18000 [==============================] - 4s 249us/step - loss: 0.0539 - acc: 0.9890 - val_loss: 0.1654 - val_acc: 0.9387\n",
      "Epoch 127/200\n",
      "18000/18000 [==============================] - 5s 274us/step - loss: 0.1242 - acc: 0.9591 - val_loss: 0.2418 - val_acc: 0.9083\n",
      "Epoch 128/200\n",
      "18000/18000 [==============================] - 5s 289us/step - loss: 0.0745 - acc: 0.9802 - val_loss: 0.1330 - val_acc: 0.9498\n",
      "Epoch 129/200\n",
      "18000/18000 [==============================] - 5s 278us/step - loss: 0.0494 - acc: 0.9904 - val_loss: 0.1306 - val_acc: 0.9555\n",
      "Epoch 130/200\n",
      "18000/18000 [==============================] - 5s 303us/step - loss: 0.0453 - acc: 0.9920 - val_loss: 0.1286 - val_acc: 0.9550\n",
      "Epoch 131/200\n",
      "18000/18000 [==============================] - 5s 282us/step - loss: 0.0414 - acc: 0.9934 - val_loss: 0.1262 - val_acc: 0.9582\n",
      "Epoch 132/200\n",
      "18000/18000 [==============================] - 5s 275us/step - loss: 0.0449 - acc: 0.9920 - val_loss: 0.1480 - val_acc: 0.9488\n",
      "Epoch 133/200\n",
      "18000/18000 [==============================] - 6s 316us/step - loss: 0.1461 - acc: 0.9521 - val_loss: 0.1866 - val_acc: 0.9338\n",
      "Epoch 134/200\n",
      "18000/18000 [==============================] - 5s 288us/step - loss: 0.0517 - acc: 0.9894 - val_loss: 0.1244 - val_acc: 0.9553\n",
      "Epoch 135/200\n",
      "18000/18000 [==============================] - 5s 278us/step - loss: 0.0394 - acc: 0.9937 - val_loss: 0.1179 - val_acc: 0.9583\n",
      "Epoch 136/200\n",
      "18000/18000 [==============================] - 5s 278us/step - loss: 0.0368 - acc: 0.9946 - val_loss: 0.1211 - val_acc: 0.9563\n",
      "Epoch 137/200\n",
      "18000/18000 [==============================] - 5s 298us/step - loss: 0.0353 - acc: 0.9944 - val_loss: 0.1155 - val_acc: 0.9600\n",
      "Epoch 138/200\n",
      "18000/18000 [==============================] - 5s 268us/step - loss: 0.0343 - acc: 0.9951 - val_loss: 0.1150 - val_acc: 0.9602\n",
      "Epoch 139/200\n",
      "18000/18000 [==============================] - 5s 290us/step - loss: 0.0337 - acc: 0.9949 - val_loss: 0.1184 - val_acc: 0.9583\n",
      "Epoch 140/200\n",
      "18000/18000 [==============================] - 6s 358us/step - loss: 0.0337 - acc: 0.9954 - val_loss: 0.1208 - val_acc: 0.9585\n",
      "Epoch 141/200\n",
      "18000/18000 [==============================] - 6s 314us/step - loss: 0.0327 - acc: 0.9951 - val_loss: 0.1163 - val_acc: 0.9595\n",
      "Epoch 142/200\n",
      "18000/18000 [==============================] - 5s 300us/step - loss: 0.0343 - acc: 0.9948 - val_loss: 0.1454 - val_acc: 0.9477\n",
      "Epoch 143/200\n",
      "18000/18000 [==============================] - 5s 282us/step - loss: 0.1550 - acc: 0.9484 - val_loss: 0.2861 - val_acc: 0.8975\n",
      "Epoch 144/200\n",
      "18000/18000 [==============================] - 5s 256us/step - loss: 0.0709 - acc: 0.9800 - val_loss: 0.1291 - val_acc: 0.9537\n",
      "Epoch 145/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0334 - acc: 0.9953 - val_loss: 0.1181 - val_acc: 0.9585\n",
      "Epoch 146/200\n",
      "18000/18000 [==============================] - 3s 192us/step - loss: 0.0306 - acc: 0.9958 - val_loss: 0.1185 - val_acc: 0.9593\n",
      "Epoch 147/200\n",
      "18000/18000 [==============================] - 3s 176us/step - loss: 0.0299 - acc: 0.9959 - val_loss: 0.1143 - val_acc: 0.9612\n",
      "Epoch 148/200\n",
      "18000/18000 [==============================] - 3s 191us/step - loss: 0.0280 - acc: 0.9965 - val_loss: 0.1199 - val_acc: 0.9580\n",
      "Epoch 149/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 0.0278 - acc: 0.9964 - val_loss: 0.1120 - val_acc: 0.9605\n",
      "Epoch 150/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0279 - acc: 0.9963 - val_loss: 0.1206 - val_acc: 0.9573\n",
      "Epoch 151/200\n",
      "18000/18000 [==============================] - 4s 211us/step - loss: 0.0271 - acc: 0.9964 - val_loss: 0.1168 - val_acc: 0.9585\n",
      "Epoch 152/200\n",
      "18000/18000 [==============================] - 4s 206us/step - loss: 0.0559 - acc: 0.9862 - val_loss: 0.3471 - val_acc: 0.8822\n",
      "Epoch 153/200\n",
      "18000/18000 [==============================] - 3s 178us/step - loss: 0.1242 - acc: 0.9577 - val_loss: 0.1649 - val_acc: 0.9430\n",
      "Epoch 154/200\n",
      "18000/18000 [==============================] - 3s 172us/step - loss: 0.0395 - acc: 0.9921 - val_loss: 0.1254 - val_acc: 0.9560\n",
      "Epoch 155/200\n",
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0278 - acc: 0.9964 - val_loss: 0.1089 - val_acc: 0.9622\n",
      "Epoch 156/200\n",
      "18000/18000 [==============================] - 3s 189us/step - loss: 0.0246 - acc: 0.9972 - val_loss: 0.1096 - val_acc: 0.9618\n",
      "Epoch 157/200\n",
      "18000/18000 [==============================] - 3s 176us/step - loss: 0.0237 - acc: 0.9974 - val_loss: 0.1107 - val_acc: 0.9628\n",
      "Epoch 158/200\n",
      "18000/18000 [==============================] - 3s 173us/step - loss: 0.0231 - acc: 0.9972 - val_loss: 0.1165 - val_acc: 0.9610\n",
      "Epoch 159/200\n",
      "18000/18000 [==============================] - 3s 169us/step - loss: 0.0229 - acc: 0.9973 - val_loss: 0.1140 - val_acc: 0.9612- loss: 0.022\n",
      "Epoch 160/200\n",
      "18000/18000 [==============================] - 3s 169us/step - loss: 0.0222 - acc: 0.9976 - val_loss: 0.1139 - val_acc: 0.9587\n",
      "Epoch 161/200\n",
      "18000/18000 [==============================] - 3s 174us/step - loss: 0.0222 - acc: 0.9976 - val_loss: 0.1212 - val_acc: 0.9582\n",
      "Epoch 162/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 0.0221 - acc: 0.9975 - val_loss: 0.1256 - val_acc: 0.9560\n",
      "Epoch 163/200\n",
      "18000/18000 [==============================] - 4s 204us/step - loss: 0.0362 - acc: 0.9927 - val_loss: 0.3600 - val_acc: 0.8878\n",
      "Epoch 164/200\n",
      "18000/18000 [==============================] - 4s 209us/step - loss: 0.1756 - acc: 0.9425 - val_loss: 0.1818 - val_acc: 0.9352\n",
      "Epoch 165/200\n",
      "18000/18000 [==============================] - 4s 206us/step - loss: 0.0441 - acc: 0.9895 - val_loss: 0.1314 - val_acc: 0.9532\n",
      "Epoch 166/200\n",
      "18000/18000 [==============================] - 4s 201us/step - loss: 0.0250 - acc: 0.9968 - val_loss: 0.1148 - val_acc: 0.9602\n",
      "Epoch 167/200\n",
      "18000/18000 [==============================] - 4s 204us/step - loss: 0.0215 - acc: 0.9978 - val_loss: 0.1116 - val_acc: 0.9603\n",
      "Epoch 168/200\n",
      "18000/18000 [==============================] - 4s 198us/step - loss: 0.0198 - acc: 0.9982 - val_loss: 0.1080 - val_acc: 0.9617\n",
      "Epoch 169/200\n",
      "18000/18000 [==============================] - 4s 204us/step - loss: 0.0189 - acc: 0.9982 - val_loss: 0.1066 - val_acc: 0.9620\n",
      "Epoch 170/200\n",
      "18000/18000 [==============================] - 4s 216us/step - loss: 0.0186 - acc: 0.9985 - val_loss: 0.1095 - val_acc: 0.9633\n",
      "Epoch 171/200\n",
      "18000/18000 [==============================] - 3s 193us/step - loss: 0.0181 - acc: 0.9982 - val_loss: 0.1102 - val_acc: 0.9627\n",
      "Epoch 172/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.0180 - acc: 0.9981 - val_loss: 0.1155 - val_acc: 0.9600\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 3s 180us/step - loss: 0.0182 - acc: 0.9982 - val_loss: 0.1104 - val_acc: 0.9602\n",
      "Epoch 174/200\n",
      "18000/18000 [==============================] - 4s 200us/step - loss: 0.0186 - acc: 0.9982 - val_loss: 0.1117 - val_acc: 0.9595\n",
      "Epoch 175/200\n",
      "18000/18000 [==============================] - 3s 194us/step - loss: 0.0188 - acc: 0.9979 - val_loss: 0.1342 - val_acc: 0.9543\n",
      "Epoch 176/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.1630 - acc: 0.9476 - val_loss: 0.2887 - val_acc: 0.9018\n",
      "Epoch 177/200\n",
      "18000/18000 [==============================] - 3s 192us/step - loss: 0.0779 - acc: 0.9756 - val_loss: 0.1581 - val_acc: 0.9452\n",
      "Epoch 178/200\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.0274 - acc: 0.9959 - val_loss: 0.1097 - val_acc: 0.9608\n",
      "Epoch 179/200\n",
      "18000/18000 [==============================] - 4s 204us/step - loss: 0.0182 - acc: 0.9984 - val_loss: 0.1074 - val_acc: 0.9613\n",
      "Epoch 180/200\n",
      "18000/18000 [==============================] - 3s 193us/step - loss: 0.0167 - acc: 0.9986 - val_loss: 0.1045 - val_acc: 0.9627\n",
      "Epoch 181/200\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.0161 - acc: 0.9988 - val_loss: 0.1066 - val_acc: 0.9607\n",
      "Epoch 182/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0155 - acc: 0.9987 - val_loss: 0.1067 - val_acc: 0.9638\n",
      "Epoch 183/200\n",
      "18000/18000 [==============================] - 4s 196us/step - loss: 0.0152 - acc: 0.9988 - val_loss: 0.1069 - val_acc: 0.9625\n",
      "Epoch 184/200\n",
      "18000/18000 [==============================] - 3s 187us/step - loss: 0.0150 - acc: 0.9989 - val_loss: 0.1096 - val_acc: 0.9627\n",
      "Epoch 185/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0148 - acc: 0.9987 - val_loss: 0.1080 - val_acc: 0.9625\n",
      "Epoch 186/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0145 - acc: 0.9988 - val_loss: 0.1099 - val_acc: 0.9630\n",
      "Epoch 187/200\n",
      "18000/18000 [==============================] - 3s 185us/step - loss: 0.0140 - acc: 0.9991 - val_loss: 0.1039 - val_acc: 0.9637\n",
      "Epoch 188/200\n",
      "18000/18000 [==============================] - 4s 197us/step - loss: 0.0138 - acc: 0.9990 - val_loss: 0.1212 - val_acc: 0.9580\n",
      "Epoch 189/200\n",
      "18000/18000 [==============================] - 3s 188us/step - loss: 0.0521 - acc: 0.9848 - val_loss: 0.3955 - val_acc: 0.8797\n",
      "Epoch 190/200\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.1648 - acc: 0.9459 - val_loss: 0.1513 - val_acc: 0.9465\n",
      "Epoch 191/200\n",
      "18000/18000 [==============================] - 3s 186us/step - loss: 0.0294 - acc: 0.9943 - val_loss: 0.1078 - val_acc: 0.9623\n",
      "Epoch 192/200\n",
      "18000/18000 [==============================] - 3s 172us/step - loss: 0.0161 - acc: 0.9989 - val_loss: 0.1032 - val_acc: 0.9640\n",
      "Epoch 193/200\n",
      "18000/18000 [==============================] - 3s 194us/step - loss: 0.0146 - acc: 0.9990 - val_loss: 0.0996 - val_acc: 0.9650\n",
      "Epoch 194/200\n",
      "18000/18000 [==============================] - 3s 170us/step - loss: 0.0134 - acc: 0.9992 - val_loss: 0.1001 - val_acc: 0.9647\n",
      "Epoch 195/200\n",
      "18000/18000 [==============================] - 3s 170us/step - loss: 0.0130 - acc: 0.9993 - val_loss: 0.0996 - val_acc: 0.9660\n",
      "Epoch 196/200\n",
      "18000/18000 [==============================] - 3s 169us/step - loss: 0.0126 - acc: 0.9993 - val_loss: 0.1037 - val_acc: 0.9642\n",
      "Epoch 197/200\n",
      "18000/18000 [==============================] - 3s 190us/step - loss: 0.0123 - acc: 0.9993 - val_loss: 0.1007 - val_acc: 0.9652\n",
      "Epoch 198/200\n",
      "18000/18000 [==============================] - 4s 216us/step - loss: 0.0121 - acc: 0.9994 - val_loss: 0.1013 - val_acc: 0.9657\n",
      "Epoch 199/200\n",
      "18000/18000 [==============================] - 4s 212us/step - loss: 0.0121 - acc: 0.9994 - val_loss: 0.1044 - val_acc: 0.9632\n",
      "Epoch 200/200\n",
      "18000/18000 [==============================] - 4s 205us/step - loss: 0.0114 - acc: 0.9994 - val_loss: 0.1042 - val_acc: 0.9643\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training = model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=200,\n",
    "              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'3 digits sub')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_acc = training.history['val_acc']\n",
    "acc = training.history['acc']\n",
    "plt.figure()\n",
    "plt.plot(val_acc, label = 'val_acc')\n",
    "plt.plot(acc, label = 'acc')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('3 digits sub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSG : Prediction\n",
      "2  Q 316-137 T 179 \u001b[91m☒\u001b[0m 189\n",
      "16  Q 233-124 T 109 \u001b[91m☒\u001b[0m 108\n",
      "19  Q 527-67  T 460 \u001b[91m☒\u001b[0m 450\n",
      "20  Q 785-784 T 1   \u001b[91m☒\u001b[0m 8  \n",
      "21  Q 39-33   T 6   \u001b[91m☒\u001b[0m 5  \n",
      "49  Q 621-579 T 42  \u001b[91m☒\u001b[0m 32 \n",
      "50  Q 209-85  T 124 \u001b[91m☒\u001b[0m 123\n",
      "51  Q 144-121 T 23  \u001b[91m☒\u001b[0m 13 \n",
      "74  Q 832-798 T 34  \u001b[91m☒\u001b[0m 44 \n",
      "103  Q 716-555 T 161 \u001b[91m☒\u001b[0m 151\n",
      "124  Q 46-44   T 2   \u001b[91m☒\u001b[0m 3  \n",
      "130  Q 505-352 T 153 \u001b[91m☒\u001b[0m 143\n",
      "139  Q 890-655 T 235 \u001b[91m☒\u001b[0m 335\n",
      "153  Q 815-813 T 2   \u001b[91m☒\u001b[0m 7  \n",
      "158  Q 960-598 T 362 \u001b[91m☒\u001b[0m 352\n",
      "160  Q 25-21   T 4   \u001b[91m☒\u001b[0m 3  \n",
      "185  Q 317-252 T 65  \u001b[91m☒\u001b[0m 55 \n",
      "187  Q 984-885 T 99  \u001b[91m☒\u001b[0m 19 \n",
      "194  Q 794-301 T 493 \u001b[91m☒\u001b[0m 483\n",
      "201  Q 573-495 T 78  \u001b[91m☒\u001b[0m 88 \n",
      "209  Q 681-130 T 551 \u001b[91m☒\u001b[0m 550\n",
      "214  Q 958-942 T 16  \u001b[91m☒\u001b[0m 26 \n",
      "224  Q 741-701 T 40  \u001b[91m☒\u001b[0m 30 \n",
      "228  Q 704-529 T 175 \u001b[91m☒\u001b[0m 166\n",
      "232  Q 401-166 T 235 \u001b[91m☒\u001b[0m 135\n",
      "235  Q 803-10  T 793 \u001b[91m☒\u001b[0m 893\n",
      "243  Q 788-691 T 97  \u001b[91m☒\u001b[0m 18 \n",
      "263  Q 742-717 T 25  \u001b[91m☒\u001b[0m 24 \n",
      "265  Q 192-3   T 189 \u001b[91m☒\u001b[0m 199\n",
      "270  Q 850-160 T 690 \u001b[91m☒\u001b[0m 790\n",
      "277  Q 26-26   T 0   \u001b[91m☒\u001b[0m 1  \n",
      "285  Q 975-784 T 191 \u001b[91m☒\u001b[0m 290\n",
      "288  Q 920-229 T 691 \u001b[91m☒\u001b[0m 791\n",
      "300  Q 515-509 T 6   \u001b[91m☒\u001b[0m 4  \n",
      "301  Q 924-865 T 59  \u001b[91m☒\u001b[0m 69 \n",
      "303  Q 616-415 T 201 \u001b[91m☒\u001b[0m 101\n",
      "307  Q 542-504 T 38  \u001b[91m☒\u001b[0m 37 \n",
      "308  Q 173-164 T 9   \u001b[91m☒\u001b[0m 1  \n",
      "311  Q 375-352 T 23  \u001b[91m☒\u001b[0m 13 \n",
      "314  Q 751-112 T 639 \u001b[91m☒\u001b[0m 649\n",
      "332  Q 61-7    T 54  \u001b[91m☒\u001b[0m 55 \n",
      "335  Q 412-354 T 58  \u001b[91m☒\u001b[0m 68 \n",
      "352  Q 638-557 T 81  \u001b[91m☒\u001b[0m 71 \n",
      "353  Q 114-90  T 24  \u001b[91m☒\u001b[0m 34 \n",
      "363  Q 498-155 T 343 \u001b[91m☒\u001b[0m 333\n",
      "365  Q 693-401 T 292 \u001b[91m☒\u001b[0m 291\n",
      "385  Q 994-122 T 872 \u001b[91m☒\u001b[0m 972\n",
      "393  Q 540-341 T 199 \u001b[91m☒\u001b[0m 299\n",
      "421  Q 430-91  T 339 \u001b[91m☒\u001b[0m 349\n",
      "429  Q 131-1   T 130 \u001b[91m☒\u001b[0m 120\n",
      "459  Q 782-767 T 15  \u001b[91m☒\u001b[0m 14 \n",
      "473  Q 313-112 T 201 \u001b[91m☒\u001b[0m 291\n",
      "492  Q 602-454 T 148 \u001b[91m☒\u001b[0m 158\n",
      "493  Q 441-371 T 70  \u001b[91m☒\u001b[0m 71 \n",
      "494  Q 847-804 T 43  \u001b[91m☒\u001b[0m 34 \n",
      "496  Q 499-212 T 287 \u001b[91m☒\u001b[0m 277\n",
      "518  Q 661-368 T 293 \u001b[91m☒\u001b[0m 393\n",
      "521  Q 870-673 T 197 \u001b[91m☒\u001b[0m 297\n",
      "527  Q 794-131 T 663 \u001b[91m☒\u001b[0m 653\n",
      "528  Q 966-426 T 540 \u001b[91m☒\u001b[0m 530\n",
      "551  Q 593-402 T 191 \u001b[91m☒\u001b[0m 180\n",
      "567  Q 68-68   T 0   \u001b[91m☒\u001b[0m 9  \n",
      "591  Q 43-40   T 3   \u001b[91m☒\u001b[0m 2  \n",
      "610  Q 734-728 T 6   \u001b[91m☒\u001b[0m 5  \n",
      "620  Q 119-90  T 29  \u001b[91m☒\u001b[0m 39 \n",
      "624  Q 680-41  T 639 \u001b[91m☒\u001b[0m 649\n",
      "628  Q 541-462 T 79  \u001b[91m☒\u001b[0m 89 \n",
      "641  Q 405-166 T 239 \u001b[91m☒\u001b[0m 240\n",
      "662  Q 498-439 T 59  \u001b[91m☒\u001b[0m 69 \n",
      "664  Q 303-253 T 50  \u001b[91m☒\u001b[0m 51 \n",
      "665  Q 859-811 T 48  \u001b[91m☒\u001b[0m 78 \n",
      "681  Q 971-349 T 622 \u001b[91m☒\u001b[0m 612\n",
      "712  Q 600-581 T 19  \u001b[91m☒\u001b[0m 39 \n",
      "731  Q 282-62  T 220 \u001b[91m☒\u001b[0m 210\n",
      "740  Q 912-119 T 793 \u001b[91m☒\u001b[0m 893\n",
      "743  Q 226-114 T 112 \u001b[91m☒\u001b[0m 111\n",
      "752  Q 139-121 T 18  \u001b[91m☒\u001b[0m 27 \n",
      "753  Q 93-31   T 62  \u001b[91m☒\u001b[0m 61 \n",
      "766  Q 286-187 T 99  \u001b[91m☒\u001b[0m 990\n",
      "767  Q 123-23  T 100 \u001b[91m☒\u001b[0m 900\n",
      "770  Q 562-468 T 94  \u001b[91m☒\u001b[0m 945\n",
      "786  Q 795-370 T 425 \u001b[91m☒\u001b[0m 424\n",
      "789  Q 516-66  T 450 \u001b[91m☒\u001b[0m 440\n",
      "798  Q 106-12  T 94  \u001b[91m☒\u001b[0m 95 \n",
      "802  Q 526-337 T 189 \u001b[91m☒\u001b[0m 199\n",
      "821  Q 921-901 T 20  \u001b[91m☒\u001b[0m 21 \n",
      "822  Q 811-784 T 27  \u001b[91m☒\u001b[0m 47 \n",
      "824  Q 95-91   T 4   \u001b[91m☒\u001b[0m 5  \n",
      "829  Q 678-508 T 170 \u001b[91m☒\u001b[0m 160\n",
      "842  Q 131-1   T 130 \u001b[91m☒\u001b[0m 120\n",
      "851  Q 161-92  T 69  \u001b[91m☒\u001b[0m 79 \n",
      "853  Q 938-90  T 848 \u001b[91m☒\u001b[0m 838\n",
      "862  Q 706-632 T 74  \u001b[91m☒\u001b[0m 75 \n",
      "873  Q 688-8   T 680 \u001b[91m☒\u001b[0m 670\n",
      "875  Q 141-94  T 47  \u001b[91m☒\u001b[0m 57 \n",
      "891  Q 694-657 T 37  \u001b[91m☒\u001b[0m 47 \n",
      "894  Q 475-196 T 279 \u001b[91m☒\u001b[0m 289\n",
      "907  Q 648-586 T 62  \u001b[91m☒\u001b[0m 72 \n",
      "909  Q 459-369 T 90  \u001b[91m☒\u001b[0m 80 \n",
      "947  Q 119-91  T 28  \u001b[91m☒\u001b[0m 37 \n",
      "951  Q 878-684 T 194 \u001b[91m☒\u001b[0m 193\n",
      "960  Q 752-700 T 52  \u001b[91m☒\u001b[0m 62 \n",
      "accu: 0.8975666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"MSG : Prediction\")\n",
    "#####################################################\n",
    "## Try to test and evaluate your model ##############\n",
    "## ex. test_x = [\"555+175\", \"860+7  \", \"340+29 \"]\n",
    "## ex. test_y = [\"730 \", \"867 \", \"369 \"] \n",
    "#####################################################\n",
    "#####################################################\n",
    "correct_ct = 0\n",
    "accuracy = 0\n",
    "for i in range(len(test_x)):\n",
    "    ind = np.random.randint(0, len(test_x))\n",
    "    rowx, rowy = test_x[np.array([ind])], test_y[np.array([ind])]\n",
    "    preds = model.predict_classes(rowx, verbose=0)\n",
    "    q = ctable.decode(rowx[0])\n",
    "    correct = ctable.decode(rowy[0])\n",
    "    guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        correct_ct = correct_ct + 1\n",
    "    else: \n",
    "        if i < 1000 :\n",
    "            print(i, ' Q', q[::-1] if REVERSE else q, end=' ')\n",
    "            print('T', correct, end=' ')\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "            print(guess)\n",
    "accuracy = correct_ct/len(test_x)\n",
    "print('accu:', accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accu: 0.8975666666666666\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
